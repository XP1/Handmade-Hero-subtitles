1
00:00:00,600 --> 00:00:01,100
Alright.

2
00:00:02,800 --> 00:00:06,000
Hello everyone, and welcome to another special handmade hero

3
00:00:06,000 --> 00:00:08,300
presentation much like yesterday.

4
00:00:08,400 --> 00:00:08,800
No program.

5
00:00:08,800 --> 00:00:13,300
Today, it's actually interview and one of the things that I wanted to

6
00:00:13,300 --> 00:00:16,700
do it, handmade conned was get all the people at rad, who work on

7
00:00:16,700 --> 00:00:20,800
compression to give us kind of an explanation of how they think about

8
00:00:20,800 --> 00:00:21,100
it.

9
00:00:21,100 --> 00:00:26,000
And sort of like for people such as myself, who don't know, a whole

10
00:00:26,000 --> 00:00:29,800
lot about the field to try to get like an expert's point of view on it

11
00:00:29,800 --> 00:00:30,200
and sort of

12
00:00:30,800 --> 00:00:33,600
Set your mind straight if you want to sort of understand compression

13
00:00:33,600 --> 00:00:38,300
things or start getting more into compression and Charles was the only

14
00:00:38,300 --> 00:00:42,700
person at rad who we didn't get to talk to him a con and he graciously

15
00:00:42,700 --> 00:00:44,900
agreed to come on the show for an interview.

16
00:00:45,300 --> 00:00:47,700
Hopefully, we'll be able to record this.

17
00:00:47,700 --> 00:00:51,200
Okay, with, with the webcam setup, we're kind of amateur at recording

18
00:00:51,200 --> 00:00:52,100
a live interview here.

19
00:00:52,100 --> 00:00:53,100
So we do the best.

20
00:00:53,100 --> 00:00:53,600
We can.

21
00:00:54,300 --> 00:00:57,100
Charles thanks so much for joining me, my pleasure.

22
00:00:57,800 --> 00:01:00,200
I want to start out by just kind of asking you sir.

23
00:01:00,300 --> 00:01:05,099
Of the same questions that I asked Fabien and Jeff a handmade con

24
00:01:05,099 --> 00:01:07,800
because I kind of wanted to know your take on it.

25
00:01:07,800 --> 00:01:10,400
But before we do you want to maybe get people who don't know a little

26
00:01:10,400 --> 00:01:14,300
bit of background because you know, I think a lot of folks probably

27
00:01:14,300 --> 00:01:16,700
don't don't know where the people at Brad came from or how they got

28
00:01:16,700 --> 00:01:16,900
there.

29
00:01:16,900 --> 00:01:18,500
So great.

30
00:01:19,400 --> 00:01:25,600
So I started in software on data compression long, long ago, probably

31
00:01:25,600 --> 00:01:29,600
20 years ago and I worked in data compression for

32
00:01:30,400 --> 00:01:33,800
Years before I transitioned into the games industry, how did you get

33
00:01:33,800 --> 00:01:35,000
started on compression?

34
00:01:36,000 --> 00:01:39,800
Why did you end up doing that as like the first thing just as a hobby?

35
00:01:39,800 --> 00:01:43,000
Kind of, oh no, I started even in like high school.

36
00:01:43,000 --> 00:01:45,600
When I had started coding, I started playing around with the data

37
00:01:45,600 --> 00:01:46,700
compression really.

38
00:01:46,700 --> 00:01:51,000
Is the way most people get into data conversion, I'd say, okay is just

39
00:01:51,000 --> 00:01:53,700
kind of out of curiosity and playing in their free time.

40
00:01:53,800 --> 00:01:54,200
All right.

41
00:01:55,300 --> 00:01:59,000
And I found it fascinating so I started playing with it more and more

42
00:01:59,000 --> 00:02:00,200
until it turned into.

43
00:02:00,300 --> 00:02:02,300
Two jobs that I started taking gun.

44
00:02:05,300 --> 00:02:08,900
And I wound up working at eclipse for Dave, Stafford were removed the

45
00:02:08,900 --> 00:02:10,300
Genesis 3D engine.

46
00:02:10,900 --> 00:02:13,600
He actually hired me to do data compression there.

47
00:02:14,200 --> 00:02:14,500
Really?

48
00:02:15,000 --> 00:02:15,300
Yeah.

49
00:02:15,300 --> 00:02:15,700
Okay.

50
00:02:15,700 --> 00:02:19,600
Because the idea at Eclipse was to do 3D on the web.

51
00:02:20,400 --> 00:02:25,500
Oh right okay so I was doing the like transmission side of that

52
00:02:25,500 --> 00:02:30,100
compressing the content you know because at the time we were a lot of

53
00:02:30,100 --> 00:02:31,800
people were still on modems, right?

54
00:02:31,800 --> 00:02:34,400
Right and bandwidth was important.

55
00:02:34,400 --> 00:02:34,900
So

56
00:02:35,100 --> 00:02:38,100
So how long I mean I guess I didn't think about that but we still

57
00:02:38,100 --> 00:02:41,800
don't really have 3D on the web today even as a practical reality of

58
00:02:41,800 --> 00:02:46,000
it sort of exist how so it's been it's been like 15 years or something

59
00:02:46,000 --> 00:02:50,400
of what a 20 years of people like maybe sort of going to be doing 3D

60
00:02:50,400 --> 00:02:51,500
on the web is a major thing.

61
00:02:51,500 --> 00:02:56,300
It's like not quite right, you know, right at the time it was kind of

62
00:02:56,300 --> 00:02:59,800
too soon in the sense that yeah, lots of computers could barely.

63
00:03:00,000 --> 00:03:04,000
Run 3D and like the web barely worked.

64
00:03:04,000 --> 00:03:04,200
Yeah.

65
00:03:04,200 --> 00:03:07,100
People were more concerned about like, hey, can we just have a web

66
00:03:07,100 --> 00:03:07,800
that works?

67
00:03:07,800 --> 00:03:08,700
Yes, opposed to.

68
00:03:08,700 --> 00:03:09,800
Let's have 3D on it.

69
00:03:11,300 --> 00:03:11,600
Okay.

70
00:03:11,600 --> 00:03:16,700
So you worked at eclipse and then somehow you end up it rad, like what

71
00:03:16,700 --> 00:03:18,400
happened in between, right?

72
00:03:18,400 --> 00:03:24,300
So from Eclipse, I kind of got interested in the 3D engine aspect of

73
00:03:24,300 --> 00:03:25,100
it, okay?

74
00:03:25,200 --> 00:03:29,600
Started working more and more and the like the 3D rendering pipeline.

75
00:03:30,200 --> 00:03:33,100
And transition into doing that as my job got it.

76
00:03:33,200 --> 00:03:38,500
So I moved over to games and worked in games for 10-15 years or

77
00:03:38,500 --> 00:03:39,300
something like that.

78
00:03:39,300 --> 00:03:46,600
Okay, eventually sort of quit games and move to rad as you know, a way

79
00:03:46,600 --> 00:03:50,100
of working near the game industry but not in evidence the periphery

80
00:03:50,100 --> 00:03:52,000
just like just on that that crust.

81
00:03:52,000 --> 00:03:52,400
Yes.

82
00:03:52,400 --> 00:03:55,700
Not having to get too deep into the actual reality of it, right?

83
00:03:56,700 --> 00:03:57,100
Okay.

84
00:03:57,100 --> 00:03:59,900
So I guess let me ask

85
00:04:00,400 --> 00:04:04,700
The couple compression questions here that we're sort of like the ones

86
00:04:04,700 --> 00:04:09,400
that I asked to hand make on so I'm curious like since you've worked

87
00:04:09,400 --> 00:04:12,000
on compression for extremely long time and just have a lot of

88
00:04:12,000 --> 00:04:13,000
experience with it.

89
00:04:13,300 --> 00:04:14,100
I'm curious.

90
00:04:14,300 --> 00:04:20,200
How do you tend to think about compression like the just as a whole,

91
00:04:20,200 --> 00:04:21,000
if that makes sense?

92
00:04:21,000 --> 00:04:23,700
Like what do you think about it in terms of is like, how do you

93
00:04:23,700 --> 00:04:24,900
visualize compressors?

94
00:04:24,900 --> 00:04:26,900
Or like just in terms of your mental space?

95
00:04:27,200 --> 00:04:28,800
Sorry that's a broad question, we'll start there.

96
00:04:28,800 --> 00:04:29,700
And then if you're like I

97
00:04:29,900 --> 00:04:30,900
I don't understand what you mean.

98
00:04:30,900 --> 00:04:32,000
I'll be more certain.

99
00:04:32,000 --> 00:04:35,700
I don't want to pre pre bias the answer, at all, if I can avoid it,

100
00:04:36,100 --> 00:04:36,800
it's great.

101
00:04:37,800 --> 00:04:39,400
It's a very broad question.

102
00:04:39,500 --> 00:04:42,600
And I mean, the answer is kind of tricky, because compressors,

103
00:04:43,900 --> 00:04:48,100
Our can all be very different or they can they can look very different

104
00:04:48,300 --> 00:04:50,200
in the way that they work.

105
00:04:51,700 --> 00:04:55,900
They're always trying to achieve the same goal but the end result can.

106
00:04:57,400 --> 00:05:00,500
The way the algorithm Works might not look at all like what they're

107
00:05:00,500 --> 00:05:01,300
actually doing.

108
00:05:03,300 --> 00:05:07,900
So kind of generally the way I think about compressors is

109
00:05:11,800 --> 00:05:15,400
I am always trying to think about the very theoretical aspect of how

110
00:05:15,400 --> 00:05:19,600
they're working, okay, in terms of like what are they actually

111
00:05:19,600 --> 00:05:21,200
expressing about the data?

112
00:05:21,500 --> 00:05:22,000
Okay?

113
00:05:22,100 --> 00:05:23,700
Like what are they trying to model?

114
00:05:23,900 --> 00:05:24,200
Okay.

115
00:05:25,600 --> 00:05:30,300
And then there's there's kind of the algorithm or how you express that

116
00:05:30,300 --> 00:05:36,000
in the machine code and that can not necessarily look very much like

117
00:05:37,600 --> 00:05:38,700
Theoretical side.

118
00:05:38,900 --> 00:05:43,800
But I'm always trying to keep those in mind as I'm working through

119
00:05:43,800 --> 00:05:44,400
things.

120
00:05:44,400 --> 00:05:47,900
What do you mean by the theoretical mod are like?

121
00:05:48,600 --> 00:05:51,300
Can you give an example of what you mean by that?

122
00:05:51,600 --> 00:05:55,700
Well, so all let's talk about compression in general.

123
00:05:55,700 --> 00:05:56,800
Yes, yes.

124
00:05:58,000 --> 00:05:59,800
So the cooler

125
00:06:00,000 --> 00:06:05,200
Best way to think about compression is always in terms of the model

126
00:06:05,200 --> 00:06:07,000
coder Paradigm, okay.

127
00:06:07,000 --> 00:06:10,400
Which is you, you have an entropy decoder on the back end, okay?

128
00:06:10,700 --> 00:06:13,100
And you have a model of the data, okay?

129
00:06:13,200 --> 00:06:17,900
So the model is trying to predict the data, okay, normally we work, in

130
00:06:17,900 --> 00:06:21,800
terms of streaming models, which I predict, either a bite at a time or

131
00:06:21,800 --> 00:06:24,600
a bit at a time or something like that, okay, though, there are more

132
00:06:24,600 --> 00:06:25,600
General models.

133
00:06:25,600 --> 00:06:29,800
Okay, so the model is trying to assign

134
00:06:30,000 --> 00:06:33,000
Probabilities to your data.

135
00:06:33,300 --> 00:06:37,100
Okay, basically watch, which data thinks is extremely likely to

136
00:06:37,100 --> 00:06:38,800
happen, broken, which data is rare?

137
00:06:39,100 --> 00:06:39,500
Okay.

138
00:06:39,600 --> 00:06:43,500
And then you entropy decoder, assigns bit lengths based on those

139
00:06:43,500 --> 00:06:44,500
probabilities.

140
00:06:44,600 --> 00:06:46,500
Okay, which is just minus log.

141
00:06:46,500 --> 00:06:49,600
2 p is the correct bit length.

142
00:06:49,700 --> 00:06:50,000
Okay.

143
00:06:50,000 --> 00:06:50,300
Okay.

144
00:06:50,300 --> 00:06:51,500
For a given probability.

145
00:06:51,500 --> 00:06:52,500
Can you expand on that?

146
00:06:52,500 --> 00:06:54,500
A little since you, since you brought it up, already, do you want to?

147
00:06:54,500 --> 00:06:55,700
And you can draw if you want to?

148
00:06:55,700 --> 00:06:57,500
I don't know if you want to, but can you expand on that for people who

149
00:06:57,500 --> 00:06:59,500
don't will immediately know what that means?

150
00:06:59,500 --> 00:06:59,800
When you say,

151
00:07:03,200 --> 00:07:05,400
Are you want to pause and go back to later?

152
00:07:06,100 --> 00:07:06,800
What?

153
00:07:06,900 --> 00:07:07,800
I don't like.

154
00:07:07,800 --> 00:07:10,300
I don't want to teach old glass of data compression as it's too

155
00:07:10,300 --> 00:07:10,900
complicated.

156
00:07:10,900 --> 00:07:11,300
Yeah.

157
00:07:11,600 --> 00:07:16,200
But if you have certain probabilities, yes, you can assign certain

158
00:07:16,200 --> 00:07:17,600
code lengths, okay?

159
00:07:17,900 --> 00:07:21,200
The code lengths are constrained by decodability.

160
00:07:21,500 --> 00:07:24,100
There's something called the Kraft inequality, okay?

161
00:07:24,100 --> 00:07:26,300
Which is a constraint on the code lengths.

162
00:07:26,300 --> 00:07:26,800
Okay.

163
00:07:26,800 --> 00:07:32,000
You can't just say every word gets a code length of 0, okay?

164
00:07:32,000 --> 00:07:32,500
Hey, you have in

165
00:07:32,700 --> 00:07:34,900
Compression, but it's not decodable.

166
00:07:35,300 --> 00:07:36,200
Okay, great.

167
00:07:36,200 --> 00:07:36,600
I see.

168
00:07:36,600 --> 00:07:42,300
So if you have, if your input is a bit, it can either be 0 or 1.

169
00:07:42,900 --> 00:07:45,900
You could have a code length of one for each of them.

170
00:07:46,000 --> 00:07:47,200
Yes, that's decodable.

171
00:07:47,300 --> 00:07:50,500
And that's no compression essentially that's a copy, right?

172
00:07:50,500 --> 00:07:51,000
Okay.

173
00:07:51,100 --> 00:07:52,400
That's both B.

174
00:07:52,900 --> 00:07:54,400
Both values of the bitter equally likely.

175
00:07:54,400 --> 00:07:54,700
Yes.

176
00:07:55,100 --> 00:08:02,300
Or you can have code lengths that are logged to pee and log2 1 - p

177
00:08:02,800 --> 00:08:04,300
okay for any PE.

178
00:08:04,600 --> 00:08:06,800
Okay, that's also decodable.

179
00:08:07,100 --> 00:08:07,600
Okay.

180
00:08:08,200 --> 00:08:12,200
Code lengths below that are going to be non decodable below.

181
00:08:12,200 --> 00:08:12,800
What?

182
00:08:14,200 --> 00:08:17,200
Log to peed log2 1, minus P for any P.

183
00:08:17,300 --> 00:08:21,000
That makes a curve of the to code lengths.

184
00:08:21,000 --> 00:08:21,600
Okay.

185
00:08:22,100 --> 00:08:22,700
And anything.

186
00:08:22,700 --> 00:08:26,600
That's anything that's in that space shorter.

187
00:08:26,700 --> 00:08:28,400
Okay, is non decodable.

188
00:08:28,800 --> 00:08:31,800
Anything longer is wasting B?

189
00:08:31,800 --> 00:08:34,299
Some inefficient entropy encoder.

190
00:08:34,400 --> 00:08:35,000
I'm not sure.

191
00:08:35,000 --> 00:08:38,000
I mean I vaguely understand that but I'm not sure.

192
00:08:38,000 --> 00:08:39,200
I totally understand that.

193
00:08:39,200 --> 00:08:43,500
So just to be clear when you're talking about code lengths, right?

194
00:08:44,100 --> 00:08:47,100
And in this case, I guess we're talking about potentially fractional,

195
00:08:47,900 --> 00:08:49,200
bit lengths, in the sense.

196
00:08:49,200 --> 00:08:49,500
Yeah.

197
00:08:49,600 --> 00:08:54,400
So so the, I mean, the optimal entropy coder would be fractional and

198
00:08:54,800 --> 00:08:56,700
infinite Precision Fit, perfect Precision, right?

199
00:08:56,700 --> 00:08:59,200
So one of the things you have to deal with is when you go to a

200
00:08:59,200 --> 00:08:59,800
practical,

201
00:09:00,000 --> 00:09:00,400
Her.

202
00:09:00,600 --> 00:09:03,600
Yeah, which is obviously not infinite Precision, right?

203
00:09:03,800 --> 00:09:08,300
It has to buy us into this slightly wasteful space, right?

204
00:09:08,500 --> 00:09:11,100
And so you want to minimize that bias, okay?

205
00:09:11,100 --> 00:09:14,800
How far you go into the wasting code space?

206
00:09:15,300 --> 00:09:19,000
And so, I think, if I can restate what you're saying about the log P?

207
00:09:19,000 --> 00:09:19,900
Part of things.

208
00:09:19,900 --> 00:09:24,000
So what you were saying there was that, like, okay, so if I have

209
00:09:24,000 --> 00:09:28,900
fractional B, I could say that I'm going to assign you know, point to

210
00:09:28,900 --> 00:09:29,500
bits.

211
00:09:30,000 --> 00:09:34,500
20 and point two bits to 1 which would give me this nice compression

212
00:09:34,500 --> 00:09:36,800
because now it only takes .4 B / B.

213
00:09:36,900 --> 00:09:40,700
But what you're saying is that can't actually exist because of that

214
00:09:40,700 --> 00:09:41,200
theorem, right?

215
00:09:41,200 --> 00:09:43,500
We have proven that, that's not possible.

216
00:09:43,600 --> 00:09:48,500
It still has to sum up to the one bit value at the end, right?

217
00:09:48,500 --> 00:09:51,100
Is that a fair statement restatement of what you're saying?

218
00:09:51,100 --> 00:09:53,300
Correct, it doesn't sum up to one bit.

219
00:09:53,500 --> 00:09:54,100
Exactly.

220
00:09:54,200 --> 00:09:55,400
Okay, they don't add up.

221
00:09:56,500 --> 00:09:58,000
They don't add up to two bits.

222
00:09:59,400 --> 00:10:04,200
okay, in order to be the what happens is when you when you save on

223
00:10:04,200 --> 00:10:06,300
one, you actually gain more on the other

224
00:10:07,500 --> 00:10:12,200
If you look at what log p and log 1 minus P do, okay?

225
00:10:12,500 --> 00:10:15,600
So like if you want to save, if you go to half a bit on one.

226
00:10:15,600 --> 00:10:17,400
Yeah, other one goes to two beds.

227
00:10:18,200 --> 00:10:19,300
Okay, right, sorry.

228
00:10:19,300 --> 00:10:24,200
So yeah, I shouldn't say sum up to 1 that it because it's in the log

229
00:10:24,200 --> 00:10:24,600
space.

230
00:10:24,600 --> 00:10:28,100
It's going to be not bad but right out of the log space.

231
00:10:28,100 --> 00:10:30,000
If it's enough to one might be a way to say it.

232
00:10:30,000 --> 00:10:30,500
I don't know how.

233
00:10:30,500 --> 00:10:30,800
Yeah.

234
00:10:30,800 --> 00:10:33,900
I know what the right way to say that is to each code length.

235
00:10:33,900 --> 00:10:34,500
Yes.

236
00:10:34,800 --> 00:10:37,200
That sums to to okay.

237
00:10:37,700 --> 00:10:38,200
Okay.

238
00:10:39,000 --> 00:10:40,600
Alright, that'll okay that all makes sense.

239
00:10:40,600 --> 00:10:44,200
Now I'm on board, okay, so back to the original statement of how you

240
00:10:44,200 --> 00:10:49,300
think about it, you were saying that you think of it as model and

241
00:10:49,300 --> 00:10:49,600
coders.

242
00:10:49,600 --> 00:10:52,200
So you basically, which I think does kind of echo.

243
00:10:52,300 --> 00:10:55,600
Although, I don't know that anyone broke it down exactly that way but

244
00:10:55,600 --> 00:10:56,700
it did sound of sound.

245
00:10:56,700 --> 00:10:59,800
Like what people had said in terms of when fobbing Jeff were talking

246
00:10:59,800 --> 00:11:00,100
about it.

247
00:11:00,100 --> 00:11:03,700
Yeah so basically the model part of things is basically saying I'm

248
00:11:03,700 --> 00:11:07,200
trying to figure out what I expect to happen in this.

249
00:11:07,300 --> 00:11:09,200
This stream as I'm seeing it.

250
00:11:09,300 --> 00:11:12,900
And the encoder part is saying, well, based on what that, you know,

251
00:11:12,900 --> 00:11:14,400
front end, sort of gas about.

252
00:11:14,400 --> 00:11:20,100
What I expect to see is I'm going to assign B to what it sort of told

253
00:11:20,100 --> 00:11:20,200
me.

254
00:11:20,200 --> 00:11:24,500
I needed to assign, I guess that makes or if you want to say that.

255
00:11:24,600 --> 00:11:28,700
I mean so the model is you have some assumptions or some knowledge

256
00:11:28,700 --> 00:11:34,700
about the data and you're trying to reduce the amount of bits that you

257
00:11:34,700 --> 00:11:37,200
have to actually send based on.

258
00:11:37,400 --> 00:11:41,500
That knowledge like if I know that you're going to be speaking English

259
00:11:41,500 --> 00:11:42,000
to me.

260
00:11:42,100 --> 00:11:42,400
Yeah.

261
00:11:42,500 --> 00:11:46,900
Then I know a huge amount about what letters you're going to be using,

262
00:11:46,900 --> 00:11:47,300
right?

263
00:11:47,300 --> 00:11:49,100
Even before you say anything, right?

264
00:11:49,400 --> 00:11:55,500
And the way that you express that knowledge precisely in a way that

265
00:11:55,500 --> 00:11:59,800
saves B is through this model coder mechanism, got

266
00:12:00,000 --> 00:12:07,100
If so, so what I'm thinking about theoretically is, what is, what is

267
00:12:07,100 --> 00:12:10,100
the model of the data that I want to create like, what do I expect

268
00:12:10,100 --> 00:12:12,500
this data to be like, and how do I express that?

269
00:12:12,500 --> 00:12:20,900
Or if I have a compressor that is not obviously, like a model, like an

270
00:12:20,900 --> 00:12:25,300
lz77 type compressor, or okay, there's a whole lot of other kind of

271
00:12:25,300 --> 00:12:26,400
heuristic compressors.

272
00:12:26,400 --> 00:12:29,600
They don't obviously appear to be

273
00:12:30,000 --> 00:12:31,500
pressed as a model, okay?

274
00:12:31,500 --> 00:12:34,600
Some you know, some compressors are more obviously expressed this way,

275
00:12:34,600 --> 00:12:35,200
okay?

276
00:12:35,400 --> 00:12:39,100
Whereas, others don't appear to be this way, and when you say lz77, as

277
00:12:39,100 --> 00:12:41,700
an example of one, that isn't expressed this way, you mean because,

278
00:12:41,700 --> 00:12:45,900
hey, it's just sort of saying I refer into the stuff in the Stream but

279
00:12:46,000 --> 00:12:47,800
I don't really beyond that.

280
00:12:47,800 --> 00:12:50,200
Have a lot of opinion about what I expect to be seeing.

281
00:12:50,300 --> 00:12:53,700
I just expect me seeing things I have seen before, that's about it.

282
00:12:53,800 --> 00:12:54,100
Great.

283
00:12:54,100 --> 00:12:59,800
So for some compressors like PPM or

284
00:13:00,200 --> 00:13:02,400
The Pact context mixing compressors.

285
00:13:02,600 --> 00:13:06,500
These compressors are very obviously making probabilities for what

286
00:13:06,500 --> 00:13:08,400
they expect the next thing to be.

287
00:13:08,500 --> 00:13:10,200
Okay and then coding based on that.

288
00:13:10,300 --> 00:13:14,100
Okay, so you very clearly see here's a model and here's a coder got it

289
00:13:14,100 --> 00:13:17,200
and the way you get more compression is to make the model, fit the

290
00:13:17,200 --> 00:13:18,600
data better, got it.

291
00:13:20,100 --> 00:13:24,200
So that is like one kind of whole realm of data compression where

292
00:13:24,200 --> 00:13:25,600
people are just working on.

293
00:13:26,300 --> 00:13:30,400
Working on making better models and I say you make better models, you

294
00:13:30,400 --> 00:13:33,800
get more compression and those models are entirely based on the data.

295
00:13:33,800 --> 00:13:36,300
So it's like hey for every type of data.

296
00:13:36,300 --> 00:13:39,200
We might be looking at any given time.

297
00:13:39,200 --> 00:13:42,900
We have to create model specific to that because the more specific it

298
00:13:42,900 --> 00:13:45,000
is to the data, the better compression were going to get out of here.

299
00:13:45,000 --> 00:13:48,400
Is the more you know about the data the more you can specialize your

300
00:13:48,400 --> 00:13:50,600
model to it and the more compression you'll get.

301
00:13:50,600 --> 00:13:51,100
All right.

302
00:13:51,100 --> 00:13:52,100
All right.

303
00:13:52,100 --> 00:13:56,100
So I guess like one thing I might ask which

304
00:13:56,400 --> 00:13:58,600
The question that I had maybe it's a little too early in the Stream

305
00:13:58,600 --> 00:14:02,500
for it but since it's already seems to come up, one question that I

306
00:14:02,500 --> 00:14:07,900
had as someone who's not a compression expert, was the split between

307
00:14:08,500 --> 00:14:13,300
prediction and entropy encoding is somewhat.

308
00:14:14,300 --> 00:14:19,400
It's not obvious at least to me based on not knowing very much.

309
00:14:19,900 --> 00:14:20,300
Why?

310
00:14:20,300 --> 00:14:25,300
That is, how things split out because even with from just a cursory

311
00:14:25,300 --> 00:14:25,800
understanding of

312
00:14:26,300 --> 00:14:26,600
Ian.

313
00:14:26,700 --> 00:14:30,000
I totally see where you're coming from with that, that model entropy

314
00:14:30,000 --> 00:14:33,600
split because most things I've ever seen also discuss it that way,

315
00:14:33,600 --> 00:14:33,900
right?

316
00:14:33,900 --> 00:14:37,300
It's like, oh, here's jpeg or here's pkzip or hears any of these

317
00:14:37,300 --> 00:14:37,500
things.

318
00:14:37,500 --> 00:14:38,700
It's like that is what they look like.

319
00:14:38,700 --> 00:14:42,300
They've got this one part that's designed to sort of like pre-process

320
00:14:42,300 --> 00:14:45,600
the stream into these pieces that then gets fed into the entropy

321
00:14:45,600 --> 00:14:46,200
encoder.

322
00:14:46,200 --> 00:14:50,000
And that's what you write out as a stream, but it's not obvious to me

323
00:14:50,000 --> 00:14:51,900
why that is, if that makes sense.

324
00:14:52,100 --> 00:14:55,400
Like, are there deeper reasons at this point as to?

325
00:14:55,400 --> 00:14:56,200
Why it's

326
00:14:56,300 --> 00:14:58,600
Natural for that to be the way that things have stood out.

327
00:14:58,600 --> 00:14:59,500
Is it a

328
00:15:00,000 --> 00:15:02,500
Our goal thing that's the reason that they stood out that way and

329
00:15:02,500 --> 00:15:06,600
maybe in the future they won't is it just because we're not good

330
00:15:06,600 --> 00:15:09,600
enough compression yet and later will realize that was dumb.

331
00:15:09,600 --> 00:15:16,100
Like can you give some perspective on that as in terms of what the Y

332
00:15:16,100 --> 00:15:18,800
as opposed to just the fact that it is because it definitely does seem

333
00:15:18,800 --> 00:15:19,300
to be.

334
00:15:21,600 --> 00:15:25,700
Well it's just a powerful and useful way to look at the problem.

335
00:15:25,700 --> 00:15:26,300
Okay.

336
00:15:28,100 --> 00:15:34,100
I mean it for one thing, you could consider the alternative right?

337
00:15:34,100 --> 00:15:34,800
Which is

338
00:15:36,200 --> 00:15:41,000
You there's they're sort of the theoretical best possible.

339
00:15:41,000 --> 00:15:46,700
Compressor is to enumerate all possible data streams of all possible

340
00:15:46,700 --> 00:15:48,000
lengths, okay?

341
00:15:48,200 --> 00:15:51,500
And either assign a probability to each one, okay?

342
00:15:51,500 --> 00:15:55,100
Or assigned an output code stream okay to each one.

343
00:15:55,200 --> 00:15:55,600
Okay.

344
00:15:55,800 --> 00:15:59,700
So you're you know, you're making this huge enumeration of all

345
00:15:59,700 --> 00:16:01,000
possible data, okay?

346
00:16:01,700 --> 00:16:05,900
Where there's like every picture we ever want to send

347
00:16:06,000 --> 00:16:06,400
Exactly.

348
00:16:06,400 --> 00:16:08,400
Is going to be in this summer, right?

349
00:16:08,400 --> 00:16:08,700
Okay.

350
00:16:08,700 --> 00:16:12,400
So if you think about this, what this data looks like, there's a

351
00:16:12,400 --> 00:16:13,800
massive amount of it.

352
00:16:14,300 --> 00:16:15,600
99% of it.

353
00:16:15,700 --> 00:16:22,300
Okay, is garbage like random bits, okay, which you would never expect

354
00:16:22,300 --> 00:16:23,900
to occur, okay?

355
00:16:23,900 --> 00:16:28,000
As like an image or text file or something like that, okay?

356
00:16:28,000 --> 00:16:29,900
Like there's you know, right?

357
00:16:30,400 --> 00:16:35,800
And then this small part of it is organized data, okay?

358
00:16:36,000 --> 00:16:39,500
so, it turns out that organized data is,

359
00:16:41,000 --> 00:16:44,600
You know, a very small amount of all possible data.

360
00:16:44,600 --> 00:16:46,600
Okay, should I?

361
00:16:46,600 --> 00:16:49,300
This sun is getting oppressive so this it's going to did I close it

362
00:16:49,300 --> 00:16:49,500
up?

363
00:16:57,900 --> 00:17:03,900
Shorter lengths, to the organize data that you expect to be seeing on

364
00:17:03,900 --> 00:17:05,400
a regular basis, okay?

365
00:17:05,700 --> 00:17:08,500
And longer code lengths, to the random data.

366
00:17:08,599 --> 00:17:09,000
Yes.

367
00:17:10,800 --> 00:17:15,000
Anytime you're doing a data compression, you're always, if you're

368
00:17:15,000 --> 00:17:17,300
compressing some data, you're expanding other data.

369
00:17:17,900 --> 00:17:18,000
Yeah.

370
00:17:18,000 --> 00:17:21,400
So your it's not like you or just getting stuff for free, you're

371
00:17:21,400 --> 00:17:23,300
choosing this data.

372
00:17:23,300 --> 00:17:24,700
I want to expand this data.

373
00:17:24,700 --> 00:17:26,000
I want to shrink got it.

374
00:17:27,700 --> 00:17:35,100
So if you could do this that then theoretically you are working with

375
00:17:35,100 --> 00:17:35,700
out.

376
00:17:36,500 --> 00:17:40,300
The specific entropy code, or you can do, you know, you can do very

377
00:17:40,300 --> 00:17:45,200
fine since you're on our file system, we're only have B accuracy.

378
00:17:45,600 --> 00:17:49,400
You can have B accuracy lengths of your output, and you can do as good

379
00:17:49,400 --> 00:17:52,400
as possible compression without ever getting into anything like

380
00:17:52,400 --> 00:17:56,000
arithmetic coding or funny stuff with fractional bits.

381
00:17:56,900 --> 00:17:59,800
And this would basically just be a case.

382
00:18:00,100 --> 00:18:03,000
Of well, would you?

383
00:18:03,000 --> 00:18:04,700
I mean, so if you actually have this case.

384
00:18:04,700 --> 00:18:09,800
So I have, you know, the, you know, 17 trillion images that were ever

385
00:18:09,800 --> 00:18:12,800
going to send or whatever and I go through and I enumerate them all

386
00:18:12,900 --> 00:18:15,100
and I say we want to be able to send all of these.

387
00:18:15,400 --> 00:18:18,600
I guess what you're saying is you now just have one number that can

388
00:18:18,600 --> 00:18:22,600
represent between 0 and 17 trillion and you just have that number that

389
00:18:22,600 --> 00:18:24,800
tells you which image you had and that's the entirety of the

390
00:18:24,800 --> 00:18:25,500
compressor.

391
00:18:26,800 --> 00:18:27,200
Her go.

392
00:18:27,200 --> 00:18:30,200
I don't have to actually have well, and the number would be different

393
00:18:30,200 --> 00:18:33,300
lengths for each of the images based on the probably the image think

394
00:18:33,300 --> 00:18:34,100
is more likely.

395
00:18:34,100 --> 00:18:36,000
So I would still have to get into arithmetic.

396
00:18:36,000 --> 00:18:39,200
Encoding, in some sense, wouldn't I or this point?

397
00:18:39,200 --> 00:18:41,700
They're just different bike lengths of okay.

398
00:18:43,300 --> 00:18:43,700
Okay.

399
00:18:43,800 --> 00:18:46,100
The first couple of bets are the length of the thing.

400
00:18:46,100 --> 00:18:46,500
Okay.

401
00:18:46,900 --> 00:18:53,200
All right so you can do that without any incremental coating or

402
00:18:53,200 --> 00:18:53,700
whatever.

403
00:18:54,200 --> 00:18:55,900
So part of the reason why we don't

404
00:18:56,100 --> 00:18:59,300
That is because we want to be able to process little by little.

405
00:18:59,800 --> 00:19:02,300
I don't want to have to have a giant table of everything, right.

406
00:19:02,300 --> 00:19:05,100
We don't have to wait until we see all the data to be able to Output

407
00:19:05,100 --> 00:19:08,700
anything got it so a lot of the work has been about how to do things

408
00:19:08,700 --> 00:19:12,500
incrementally which is where things like arithmetic coding.

409
00:19:12,500 --> 00:19:13,300
Come from.

410
00:19:13,300 --> 00:19:13,700
Okay.

411
00:19:13,700 --> 00:19:22,600
It's just the ability to what you're trying to do is create a kind of

412
00:19:22,600 --> 00:19:25,900
an expression of a multi symbol.

413
00:19:26,000 --> 00:19:30,800
All probability estimation but to do it one at a time.

414
00:19:31,900 --> 00:19:32,400
Okay.

415
00:19:33,000 --> 00:19:36,400
You mean one at a time being, as the symbols come in, you're changing

416
00:19:36,400 --> 00:19:38,200
your estimates of their probability.

417
00:19:38,200 --> 00:19:39,600
Or what do you mean by one at a time?

418
00:19:40,400 --> 00:19:41,700
Maybe I can draw sure.

419
00:19:42,500 --> 00:19:43,100
Go nuts.

420
00:19:44,700 --> 00:19:46,100
Just should be live.

421
00:19:46,500 --> 00:19:49,700
So what you're trying to do is

422
00:19:53,600 --> 00:19:58,100
You have some multi symbol sequence and you want to give a code length

423
00:19:58,100 --> 00:19:58,700
to it?

424
00:20:00,000 --> 00:20:02,100
Based on the various codes in it.

425
00:20:03,300 --> 00:20:06,600
But you don't want to have to deal with lots of things at a time like

426
00:20:06,600 --> 00:20:07,200
that.

427
00:20:07,600 --> 00:20:09,000
You want to be able to do it incrementally.

428
00:20:09,000 --> 00:20:12,200
So you express the probability of the whole sequence.

429
00:20:13,200 --> 00:20:19,600
As you know, the probability of four characters is the probability of

430
00:20:19,600 --> 00:20:24,800
one, given the previous three times, the probability of the previous

431
00:20:24,800 --> 00:20:25,300
3,

432
00:20:27,700 --> 00:20:29,800
And then, you can go ahead and place this in the same way.

433
00:20:33,700 --> 00:20:35,200
Are those in reverse order?

434
00:20:35,700 --> 00:20:38,600
Yeah, okay, I'm doing confusingly reverse order, okay?

435
00:20:38,600 --> 00:20:40,500
Because that's going to say like, I'm cutting my stream.

436
00:20:40,500 --> 00:20:41,800
Backward, you cutting your name backwards?

437
00:20:41,800 --> 00:20:42,600
Yeah, all right.

438
00:20:43,500 --> 00:20:47,000
Wait, is that because you guys do do streams backwards now with Rands

439
00:20:47,000 --> 00:20:48,500
is here right at all?

440
00:20:48,500 --> 00:20:51,200
This like if you hold down the spacebar, you can scroll around to if

441
00:20:51,200 --> 00:20:53,900
you want to try to put a probability of D down here and right, and

442
00:20:53,900 --> 00:20:54,300
fair enough.

443
00:20:54,500 --> 00:20:59,600
So, you know, this is just a way of expressing instead of

444
00:21:01,000 --> 00:21:04,100
Is make sure that yeah, it did work, you know?

445
00:21:04,100 --> 00:21:11,300
I mean like so like you may think of word estimation like the if

446
00:21:11,300 --> 00:21:14,300
you're doing text, the important thing is the probability of the word

447
00:21:14,800 --> 00:21:16,000
occurring, right?

448
00:21:16,300 --> 00:21:17,800
But you don't want to have to wait.

449
00:21:17,800 --> 00:21:21,500
You want to have to buffer up, lots of things before you run through

450
00:21:21,500 --> 00:21:24,000
your model and kind of you want to go one at a time.

451
00:21:24,000 --> 00:21:29,200
So we have a probability of T first and then probability of H with t

452
00:21:29,200 --> 00:21:30,300
following and then probably go.

453
00:21:30,700 --> 00:21:35,500
E, th proceeding got it, I kind of thing.

454
00:21:36,100 --> 00:21:41,500
So the arithmetic coder then allows you to Output from each step of

455
00:21:41,500 --> 00:21:46,900
the coating and accumulate into a streaming output, instead of having

456
00:21:46,900 --> 00:21:50,900
to wait until you see the full probability to create the correct code

457
00:21:50,900 --> 00:21:51,300
length.

458
00:21:53,000 --> 00:21:55,700
And even if you, but even if you didn't, you'd still need some like,

459
00:21:55,700 --> 00:21:58,500
arithmetic encoding, assuming that you wanted, those code likes to be

460
00:21:58,500 --> 00:21:59,500
fractional, right?

461
00:22:00,500 --> 00:22:03,200
I mean, because, you know, we need some strategy to what I'm trying to

462
00:22:03,200 --> 00:22:04,200
get at is that

463
00:22:05,700 --> 00:22:09,600
If you buffered up until you got to the end of your file, you don't

464
00:22:09,600 --> 00:22:11,800
need fractional code, lengths, really?

465
00:22:11,900 --> 00:22:14,100
Because you're outputting B in the end.

466
00:22:15,800 --> 00:22:17,900
You only need fractional, code lengths, because you're doing a

467
00:22:17,900 --> 00:22:19,100
character at a time.

468
00:22:19,500 --> 00:22:23,200
And you want, you don't want to be flushing to B after each character

469
00:22:23,500 --> 00:22:25,900
because that would be an enormous weight waist.

470
00:22:26,500 --> 00:22:29,000
But when you get to the end of your file, you are flushing to B.

471
00:22:29,600 --> 00:22:33,100
So if you're if you were just creating code lengths, at the end of

472
00:22:33,100 --> 00:22:35,800
your file, you don't need fractional wings.

473
00:22:36,400 --> 00:22:36,600
Okay.

474
00:22:36,600 --> 00:22:41,300
So I don't think I understand that then because I mean let me just

475
00:22:41,300 --> 00:22:44,900
sort of say how I was thinking about it and you can tell me why this

476
00:22:44,900 --> 00:22:45,400
is wrong.

477
00:22:46,000 --> 00:22:48,000
So my understanding was that.

478
00:22:48,000 --> 00:22:52,500
Okay, so if I'm going to Output a bunch of stuff I've got, you know,

479
00:22:52,500 --> 00:22:55,300
all these symbols that I want to stuff, you know, and I want I'm

480
00:22:55,300 --> 00:22:57,200
trying to tell you the order these symbols came in.

481
00:22:57,500 --> 00:23:00,600
So even if I assume that I already know, like, let's assume that I

482
00:23:00,700 --> 00:23:03,000
looked at the entire piece of data, I don't know, maybe it's small,

483
00:23:03,000 --> 00:23:04,100
its 32k or something.

484
00:23:04,100 --> 00:23:06,200
So I look at the entire thing I count up.

485
00:23:06,200 --> 00:23:09,200
However, I choose to partition this into symbols, I partitioned it.

486
00:23:09,500 --> 00:23:13,700
I count up the occurrence of all of those symbols and now I know a

487
00:23:13,700 --> 00:23:15,500
specific frequency for each symbol but

488
00:23:15,900 --> 00:23:17,300
Frequency is fractional, right?

489
00:23:17,300 --> 00:23:21,200
So it's like if there were 2,000 symbols and this one appeared like

490
00:23:21,200 --> 00:23:22,400
three times it's three over.

491
00:23:22,400 --> 00:23:26,200
Two thousand is the, you know, the frequency, right?

492
00:23:27,200 --> 00:23:30,100
So at that point, when I want to go to Output these things out, I

493
00:23:30,100 --> 00:23:33,000
thought that the idea behind the arithmetic compressor was simply that

494
00:23:33,000 --> 00:23:37,700
well I probably don't want to use say, 3 bits to represent this

495
00:23:37,700 --> 00:23:38,300
symbol.

496
00:23:38,400 --> 00:23:41,800
I want to use three point two bits to represent this symbol because

497
00:23:41,800 --> 00:23:45,400
that's the closest to the frequency that I could get.

498
00:23:45,700 --> 00:23:46,300
Ergo.

499
00:23:46,300 --> 00:23:48,500
It doesn't matter if I'm flushing to b or not.

500
00:23:48,500 --> 00:23:51,300
I still want to pack these things as tightly as possible to make the

501
00:23:51,300 --> 00:23:52,500
smallest Stream.

502
00:23:52,900 --> 00:23:56,400
So I still want something like an arithmetic encoders so that I can

503
00:23:56,400 --> 00:23:59,400
always have fractional B in terms of the length of encoding.

504
00:23:59,400 --> 00:23:59,500
A

505
00:24:00,000 --> 00:24:00,500
Simple.

506
00:24:00,800 --> 00:24:03,000
Is that an incorrect way of thinking about the problem?

507
00:24:03,300 --> 00:24:03,600
It's true.

508
00:24:03,600 --> 00:24:06,500
If you're encoding one symbol, okay.

509
00:24:07,600 --> 00:24:10,600
But that's what I'm talking about is the difference between

510
00:24:10,600 --> 00:24:14,000
incremental, coding versus but even if I'm encoding a whole thing,

511
00:24:14,000 --> 00:24:17,500
don't I still have to encode the symbols one, by one in terms of

512
00:24:17,600 --> 00:24:20,100
telling the other side, what to produce?

513
00:24:20,100 --> 00:24:23,400
No, you don't have, you never have to code things, one by one.

514
00:24:23,400 --> 00:24:24,400
You have lots of choices.

515
00:24:24,900 --> 00:24:25,200
Okay.

516
00:24:25,200 --> 00:24:28,000
So tell me more about that then just, you know, again to solve it for

517
00:24:28,000 --> 00:24:30,400
people who are not familiar with this sort of stuff or not.

518
00:24:30,400 --> 00:24:37,200
For example, consider that you have data that only has orders you

519
00:24:37,600 --> 00:24:39,800
Correlation of order 0 statistics.

520
00:24:39,900 --> 00:24:41,000
Okay, by that.

521
00:24:41,100 --> 00:24:46,400
What I mean is that you have two symbols 0 and 1, okay?

522
00:24:46,700 --> 00:24:52,600
And they have some different probabilities not based on the where they

523
00:24:52,600 --> 00:24:55,200
are in the Stream it's just always the same probability everywhere

524
00:24:55,300 --> 00:24:55,500
right?

525
00:24:55,500 --> 00:24:59,600
So order 0 means there's no it doesn't correspond to whether the

526
00:24:59,600 --> 00:25:02,300
previous symbol is actually a 0 or 1 or not.

527
00:25:02,300 --> 00:25:07,000
It's just each time you see a new symbol it has no relation to what

528
00:25:07,000 --> 00:25:07,300
you've seen.

529
00:25:07,400 --> 00:25:08,500
In the past, got it.

530
00:25:08,500 --> 00:25:12,200
But there's a different probability of a big zero or one God can so

531
00:25:13,200 --> 00:25:14,500
anytime you have data.

532
00:25:14,900 --> 00:25:16,000
So first, I'll say that.

533
00:25:16,200 --> 00:25:22,300
One of the goals of data compression sometimes is to transform your

534
00:25:22,300 --> 00:25:26,700
data into order zero data Isis.

535
00:25:27,200 --> 00:25:30,900
If you have order zero data, then we know how to compress it

536
00:25:30,900 --> 00:25:32,700
perfectly, right?

537
00:25:32,700 --> 00:25:36,100
Because now, you don't need Markov chains and all these other sorts of

538
00:25:36,100 --> 00:25:37,300
things that are trying to look at.

539
00:25:37,400 --> 00:25:38,800
Where we are in the Stream and stuff.

540
00:25:38,800 --> 00:25:41,400
You're basically saying, hey, if you can transform it into this, it

541
00:25:41,400 --> 00:25:42,600
gets much simpler way.

542
00:25:43,000 --> 00:25:46,600
So one of the ways of approaching data compression is to try to find a

543
00:25:46,600 --> 00:25:51,700
d correlating transform so that you get into order zero data, then we

544
00:25:51,700 --> 00:25:53,500
have solutions for it, okay?

545
00:25:53,500 --> 00:25:56,000
So if you're trying to compress order zero data, got it.

546
00:25:57,300 --> 00:25:59,600
If you want to go bit by bit,

547
00:26:01,200 --> 00:26:04,700
Then you almost certainly want an arithmetic code or an A and S coder

548
00:26:04,700 --> 00:26:05,900
or something like that.

549
00:26:06,100 --> 00:26:10,700
Got it has to be able to do fractional B because right, doing, you

550
00:26:10,700 --> 00:26:14,300
know, integer numbers of bits when you only have 0 and 1 as input.

551
00:26:14,300 --> 00:26:14,500
Right?

552
00:26:14,500 --> 00:26:16,200
Not very useful right?

553
00:26:16,900 --> 00:26:17,400
Yes.

554
00:26:17,700 --> 00:26:21,400
But if you don't want to do one at a time, okay, there are lots of

555
00:26:21,400 --> 00:26:21,900
solutions.

556
00:26:22,000 --> 00:26:24,000
Okay, so yeah, tell me, give me a little.

557
00:26:24,000 --> 00:26:26,800
I mean, I was just at it's a brief things like kind of have it in my

558
00:26:26,800 --> 00:26:28,600
head space of, like, wait, what's there?

559
00:26:28,700 --> 00:26:30,800
So one of the possibilities is

560
00:26:31,000 --> 00:26:31,600
Of coating.

561
00:26:31,600 --> 00:26:38,500
Okay, what you do is you send first either the you take some block,

562
00:26:38,500 --> 00:26:39,000
okay?

563
00:26:39,400 --> 00:26:43,000
You send the number of zeros or the number of 1s, okay?

564
00:26:43,700 --> 00:26:48,700
And then you know that you're just trying to send an arrangement of

565
00:26:48,700 --> 00:26:50,600
where those ones are zeros far.

566
00:26:50,800 --> 00:26:51,400
Okay?

567
00:26:51,800 --> 00:26:54,500
Since it's order, zero, there's no bias for them to be rights

568
00:26:54,500 --> 00:26:55,900
particular place, right?

569
00:26:56,000 --> 00:26:59,700
So now this is just a common, a Torx problem,

570
00:27:00,200 --> 00:27:02,800
you you you know it's a choose

571
00:27:04,600 --> 00:27:08,400
There are three ones and I have to put them in eight buckets, right?

572
00:27:08,400 --> 00:27:09,500
There's you know,

573
00:27:10,600 --> 00:27:13,900
However, many I see is you can put them and now you just you just have

574
00:27:13,900 --> 00:27:16,600
to send which one is of that, okay?

575
00:27:16,900 --> 00:27:21,200
So you count, how many ways there are, and you send it a number that

576
00:27:21,200 --> 00:27:24,000
is which one of them is it from one of those icy?

577
00:27:24,500 --> 00:27:30,000
And so you you initially chose, oh, a block length to do this in, I

578
00:27:30,000 --> 00:27:34,300
see as that block, length, gets larger, you get closer and closer to

579
00:27:34,300 --> 00:27:36,100
the entropy becomes a perfect coder.

580
00:27:37,300 --> 00:27:38,000
Interesting.

581
00:27:38,500 --> 00:27:39,700
So that is a way.

582
00:27:39,800 --> 00:27:44,500
So in theory, if you wanted to, you could have just done the entire

583
00:27:44,500 --> 00:27:45,400
block this way.

584
00:27:45,400 --> 00:27:49,000
And then you wouldn't have need arithmetic and you have compressed it

585
00:27:49,000 --> 00:27:53,800
down to roughly the fractional bit way that the arithmetic would have

586
00:27:53,800 --> 00:27:54,100
done it.

587
00:27:54,100 --> 00:27:55,200
Wait, I see.

588
00:27:55,900 --> 00:28:01,100
Okay, similarly you can do Huffman coding on, you know you take eight

589
00:28:01,100 --> 00:28:03,100
or 16 of your bits at a time.

590
00:28:03,800 --> 00:28:06,600
I say you do Huffman coding on it and you're getting again closer,

591
00:28:06,600 --> 00:28:09,600
depending how big that block is you get closer and closer, you're

592
00:28:09,600 --> 00:28:12,000
wasting at most a bit on average.

593
00:28:12,000 --> 00:28:13,800
It's less than half a bit icy.

594
00:28:15,000 --> 00:28:18,300
And then, as that block, gets bigger, you're wasting loss.

595
00:28:18,400 --> 00:28:19,000
I see.

596
00:28:19,700 --> 00:28:21,100
Okay, thank you.

597
00:28:21,100 --> 00:28:21,900
That was actually very.

598
00:28:22,000 --> 00:28:22,900
There's also.

599
00:28:23,600 --> 00:28:26,300
Okay, optimal ways to do run length coding.

600
00:28:27,200 --> 00:28:32,100
If really, if one of the probabilities is biased, okay?

601
00:28:32,100 --> 00:28:33,400
You know if one of them is

602
00:28:33,900 --> 00:28:38,100
Zero tax, you typically have, you know, lots of 0 B than a one bit.

603
00:28:38,200 --> 00:28:38,600
Okay?

604
00:28:38,700 --> 00:28:41,600
So one bits are sparse bring this file.

605
00:28:41,700 --> 00:28:44,900
So in in the case that one bits are sparse.

606
00:28:44,900 --> 00:28:49,200
Yeah, you can code run lengths with

607
00:28:51,200 --> 00:28:54,000
I believe column coding is the best way to do it.

608
00:28:54,000 --> 00:28:57,600
Okay, this is what Golem coding like the little girl with the ring in

609
00:28:57,900 --> 00:28:59,800
the ring is that we're talking about here.

610
00:29:00,300 --> 00:29:03,400
I could be wrong about that but okay one of the like classic a

611
00:29:03,400 --> 00:29:07,500
precious coder classic variable-length integer codes is optimal for

612
00:29:07,500 --> 00:29:11,000
run length coding okay for for bias cases.

613
00:29:11,100 --> 00:29:11,600
Okay.

614
00:29:11,600 --> 00:29:13,200
And again that's an entropy decoder.

615
00:29:13,200 --> 00:29:16,100
Okay though it doesn't, it doesn't necessarily look like an entropy

616
00:29:16,100 --> 00:29:16,600
encoder.

617
00:29:17,800 --> 00:29:18,500
Okay.

618
00:29:19,100 --> 00:29:21,500
Well, so popping back out of that then.

619
00:29:22,300 --> 00:29:29,700
So back to the question of model versus entropy encoding.

620
00:29:30,400 --> 00:29:33,300
So I was kind of saying, is there anything else you want to say about,

621
00:29:33,300 --> 00:29:35,300
why it tends to break down that way?

622
00:29:36,000 --> 00:29:39,200
Like I guess I'd also be interested in since you're pretty theoretical

623
00:29:39,200 --> 00:29:40,600
compression kind of person to.

624
00:29:40,600 --> 00:29:42,500
I would guess I'd be interested to know, like,

625
00:29:44,000 --> 00:29:47,500
Is that you support that break down?

626
00:29:47,500 --> 00:29:49,200
Or is that break down fairly practical?

627
00:29:49,200 --> 00:29:49,400
Dude?

628
00:29:49,400 --> 00:29:49,700
You know what?

629
00:29:49,700 --> 00:29:50,900
I'm sort of getting out there.

630
00:29:50,900 --> 00:29:54,900
Like, it's like, does the theory suggests that in general coder should

631
00:29:54,900 --> 00:29:55,700
be split this way?

632
00:29:55,700 --> 00:29:57,400
Or is it more just like in practice?

633
00:29:57,400 --> 00:29:59,800
It turns out to be better to slip this way for a number of reasons.

634
00:30:00,000 --> 00:30:00,600
Sort of thing.

635
00:30:01,100 --> 00:30:01,600
It's

636
00:30:03,200 --> 00:30:07,800
so I'd say that it's a way of understanding the problem in.

637
00:30:07,800 --> 00:30:12,900
It clear way where you don't get yourself in trouble because you okay,

638
00:30:13,200 --> 00:30:15,100
if you're using a valid entropy coder.

639
00:30:15,200 --> 00:30:18,600
Yeah, you know you're always making decodable bit streams, right?

640
00:30:18,700 --> 00:30:21,600
So you aren't you know you're trying to make a perpetual motion

641
00:30:21,600 --> 00:30:22,400
machine, right?

642
00:30:22,400 --> 00:30:23,500
Right ways a hazard.

643
00:30:23,500 --> 00:30:24,000
Yes.

644
00:30:25,700 --> 00:30:28,200
And it gives you something clear to work on which is the model.

645
00:30:28,600 --> 00:30:29,600
So it's just like

646
00:30:30,400 --> 00:30:33,100
We have an entropy encoder which is well understood.

647
00:30:33,100 --> 00:30:36,100
And all we have to do is make the model fit the data better, okay?

648
00:30:36,100 --> 00:30:41,800
And it's something that you can go and iterate on and, you know, it's

649
00:30:41,800 --> 00:30:44,300
just a way of expressing the problem in a way that's easy to

650
00:30:44,300 --> 00:30:46,500
understand and analyze.

651
00:30:49,000 --> 00:30:52,100
Is opposed to, you know, the more heuristic data compressors.

652
00:30:52,900 --> 00:30:54,100
It's hard to tell.

653
00:30:54,400 --> 00:30:55,300
It's hard to analyze them.

654
00:30:55,300 --> 00:30:56,200
Mathematically.

655
00:30:56,300 --> 00:30:59,500
What are the more heuristic like what he is there?

656
00:30:59,500 --> 00:31:02,300
An example, if people want to look up a compressor that would fall

657
00:31:02,300 --> 00:31:06,000
into the category of harder to analyze, what kind of compressor might

658
00:31:06,000 --> 00:31:06,500
that be

659
00:31:10,200 --> 00:31:18,100
Well, a lot of the classic ones, so like that's a good question.

660
00:31:18,100 --> 00:31:18,700
Okay.

661
00:31:19,400 --> 00:31:25,400
Most of the ones that are obvious like lz77 have been analyzed in a

662
00:31:25,400 --> 00:31:29,900
semester later, okay, that we understand them as models now, okay,

663
00:31:30,300 --> 00:31:33,100
they don't, they didn't appear originally to be models.

664
00:31:33,100 --> 00:31:33,700
Okay?

665
00:31:34,300 --> 00:31:35,900
But now we know they are, okay.

666
00:31:36,400 --> 00:31:39,800
Things like block sorting, there are still

667
00:31:40,700 --> 00:31:42,600
Their difficulties in.

668
00:31:43,900 --> 00:31:46,100
How we understand these as models.

669
00:31:46,700 --> 00:31:51,500
I said in a practical sense and I guess, would I be correct in saying?

670
00:31:51,500 --> 00:31:55,500
It sounds like, I mean, just from again, from hearing about it or for

671
00:31:55,500 --> 00:31:57,300
the limited amount that I know about it.

672
00:31:57,600 --> 00:32:02,000
It seems to be sort of that entropy encoding seems to be much better

673
00:32:02,000 --> 00:32:03,000
solved.

674
00:32:03,000 --> 00:32:07,900
In terms of like, hey, in term, we can give you a particular

675
00:32:07,900 --> 00:32:10,000
definition of a problem.

676
00:32:10,100 --> 00:32:12,500
And then we can give you an interview coder that like exactly solves

677
00:32:12,500 --> 00:32:13,300
that problem.

678
00:32:13,700 --> 00:32:19,200
Whereas data modeling feels a little bit less like that so far, like

679
00:32:19,200 --> 00:32:19,700
it's more.

680
00:32:20,000 --> 00:32:23,400
It feels like it's a little more wild Westy in the sense that, you

681
00:32:23,400 --> 00:32:29,600
know, I get is part of the reason you break that up is because hey,

682
00:32:29,600 --> 00:32:33,500
entropy coding is very well solved to, you know, for certain specified

683
00:32:33,500 --> 00:32:33,900
problems.

684
00:32:33,900 --> 00:32:38,000
So you can just take that part out of your equation and be focusing on

685
00:32:38,000 --> 00:32:39,800
the part, that's maybe less solved.

686
00:32:39,800 --> 00:32:41,200
Is that a reasonable way to phrase it?

687
00:32:41,200 --> 00:32:42,500
Or is that not really true?

688
00:32:42,600 --> 00:32:43,100
Yeah.

689
00:32:43,100 --> 00:32:43,400
Okay.

690
00:32:43,500 --> 00:32:44,600
That's a good way to phrase it.

691
00:32:44,700 --> 00:32:50,200
I mean, it's so entropy coding, we thought that we knew all the

692
00:32:50,200 --> 00:32:54,100
entropy coders and Elaine has appeared out of nowhere top.

693
00:32:54,100 --> 00:32:57,000
Why is it since since you guys did some of the pioneering work on this

694
00:32:57,300 --> 00:32:59,300
in terms of shipping, ANS encoders

695
00:33:01,100 --> 00:33:03,500
Talk a little bit about that, because that was an interesting

696
00:33:04,000 --> 00:33:04,700
inflection point.

697
00:33:04,700 --> 00:33:09,000
I suppose, for people who don't know about ANS encoders, who aren't

698
00:33:09,000 --> 00:33:11,600
familiar with that give can give a little back when I like, what

699
00:33:11,600 --> 00:33:15,200
happened there, because this was an odd, an odd story and subset.

700
00:33:15,200 --> 00:33:17,400
Yeah, very, very odd story.

701
00:33:17,500 --> 00:33:17,800
Yeah.

702
00:33:19,000 --> 00:33:25,900
So this guy jarek Duda become years ago, four or five years ago.

703
00:33:26,000 --> 00:33:26,400
Okay,

704
00:33:28,300 --> 00:33:35,600
Wrote a paper about asymmetric numeral systems and like, lattice and

705
00:33:35,600 --> 00:33:36,200
coding.

706
00:33:36,300 --> 00:33:36,600
Okay?

707
00:33:36,600 --> 00:33:41,800
And it's so, a lot of people noticed it, okay?

708
00:33:41,800 --> 00:33:45,200
Like, I noticed it and commented, hey, this looks interesting.

709
00:33:45,300 --> 00:33:47,200
How did you find this paper?

710
00:33:47,300 --> 00:33:48,200
You were like,

711
00:33:50,200 --> 00:33:53,200
I mean cuz it's like not very many people, that's really knew about

712
00:33:53,200 --> 00:33:53,500
it.

713
00:33:53,500 --> 00:33:56,600
I'm listening, I don't recall but I'm guessing it on someone else's.

714
00:33:57,800 --> 00:34:03,000
Blog or something was like, Hey I noticed there's nobody really

715
00:34:03,000 --> 00:34:03,600
understood it.

716
00:34:03,600 --> 00:34:08,199
I didn't understand it okay because it's the original paper was

717
00:34:08,199 --> 00:34:12,300
written in a very abstract mathematical obtuse way.

718
00:34:12,400 --> 00:34:12,900
Okay?

719
00:34:13,000 --> 00:34:17,300
Nobody really saw how that the Practical implementation of that would

720
00:34:17,300 --> 00:34:20,199
look, okay, so people kind of read the paper and we're like, all

721
00:34:20,199 --> 00:34:20,600
right?

722
00:34:20,600 --> 00:34:22,100
That looks kind of interesting.

723
00:34:22,100 --> 00:34:23,199
Not sure.

724
00:34:23,199 --> 00:34:25,699
I get why or how we would use it.

725
00:34:26,199 --> 00:34:27,000
But hey, so

726
00:34:27,500 --> 00:34:28,699
Let me back up a tiny bit.

727
00:34:28,699 --> 00:34:36,100
Sure on entropy coding like with arithmetic coding.

728
00:34:37,400 --> 00:34:45,600
It's very easy to understand how to write a bad Earth metal coder or

729
00:34:45,600 --> 00:34:45,699
one.

730
00:34:45,699 --> 00:34:47,500
That doesn't work very like, okay.

731
00:34:47,500 --> 00:34:53,800
That the that, the implementation is terrible, okay, slow, or the most

732
00:34:53,800 --> 00:34:55,400
obvious way to write it requires.

733
00:34:55,400 --> 00:34:59,100
Buffering up the entire data with infinite Precision or their

734
00:34:59,100 --> 00:35:01,300
arithmetic, right?

735
00:35:01,300 --> 00:35:04,000
So there's the tricky bit about arithmetic.

736
00:35:04,000 --> 00:35:06,000
Coders is

737
00:35:07,200 --> 00:35:09,700
How do you translate it into an implementation?

738
00:35:10,100 --> 00:35:11,400
How do you make it incremental?

739
00:35:11,600 --> 00:35:12,300
You know, huh?

740
00:35:12,500 --> 00:35:20,000
Like how does it work with with finite precision and that kind of step

741
00:35:20,400 --> 00:35:23,000
is a little bit?

742
00:35:26,500 --> 00:35:29,900
It's not, there's not a formula necessarily for how to make your

743
00:35:29,900 --> 00:35:30,700
arithmetic odor.

744
00:35:30,800 --> 00:35:31,100
Okay.

745
00:35:31,100 --> 00:35:33,700
There have been many over the years, there are a lot of different ways

746
00:35:33,700 --> 00:35:34,300
to do it.

747
00:35:34,300 --> 00:35:38,200
Yes and there continue to be Innovations in that.

748
00:35:38,200 --> 00:35:43,600
Okay, as we have found slightly different ways of expressing the

749
00:35:43,600 --> 00:35:44,400
operation.

750
00:35:46,900 --> 00:35:54,900
So ans originally looked like, a new way of expressing the algorithmic

751
00:35:54,900 --> 00:35:57,200
operation of entropy coding.

752
00:35:57,300 --> 00:35:59,800
Okay, which if that's all it was, it's not very

753
00:36:00,100 --> 00:36:02,000
Staying and since the okay.

754
00:36:02,000 --> 00:36:06,500
So basically like at first it was kind of like, oh, hey, someone did

755
00:36:06,500 --> 00:36:10,800
some theoretical work here but it's not immediately clear that this

756
00:36:10,800 --> 00:36:16,700
would change, how we would actually type code into a computer or it

757
00:36:17,000 --> 00:36:20,200
you know, it was a different mathematical way of expressing entropy

758
00:36:20,200 --> 00:36:24,200
entropy coding, but it wasn't obvious that if we type that into a

759
00:36:24,200 --> 00:36:27,700
computer, it would be efficient at, all right, which is what we're

760
00:36:27,700 --> 00:36:28,400
interested in, right?

761
00:36:28,400 --> 00:36:28,800
Got it.

762
00:36:28,800 --> 00:36:29,900
We already have entropy.

763
00:36:30,000 --> 00:36:33,300
Ders, that get us as close to the entropy as we want, right?

764
00:36:33,300 --> 00:36:34,700
That is not the issue, right?

765
00:36:34,700 --> 00:36:38,100
It's a question of how efficient can it be a problem?

766
00:36:38,100 --> 00:36:44,300
Being, that efficient arithmetic coders are difficult.

767
00:36:44,800 --> 00:36:46,200
Yes, there's issues.

768
00:36:47,500 --> 00:36:47,700
Right?

769
00:36:47,700 --> 00:36:50,600
Huffman is much faster than arithmetic in those days, right?

770
00:36:50,600 --> 00:36:54,700
Like meaning you, you typically had a significant speed difference.

771
00:36:54,700 --> 00:36:58,100
I remember, especially at some point, there was sort of like, oh, it

772
00:36:58,100 --> 00:36:59,900
was kind of a divided per symbol or

773
00:37:00,000 --> 00:37:02,600
Then they were like, kind of table driven methods for arithmetic or

774
00:37:02,600 --> 00:37:06,600
whatever but they were much more complicated than the Huffman kind,

775
00:37:06,600 --> 00:37:09,300
which could just go direct and be very fast.

776
00:37:09,300 --> 00:37:12,200
Apparently, this is going very cursory knowledge, my advice.

777
00:37:12,200 --> 00:37:17,500
Remember the sat/rad at the time when I was there that was seem to be

778
00:37:17,500 --> 00:37:18,200
kind of the case.

779
00:37:18,200 --> 00:37:19,000
So yeah.

780
00:37:19,600 --> 00:37:23,600
So like doing faster that coding is a whole huge field.

781
00:37:23,600 --> 00:37:25,300
Yeah there's tons of approaches.

782
00:37:25,300 --> 00:37:26,900
Got it table based approaches.

783
00:37:27,200 --> 00:37:29,200
You can go binary and

784
00:37:30,300 --> 00:37:30,500
Yeah.

785
00:37:30,500 --> 00:37:33,100
So but they all have drawbacks, you know.

786
00:37:33,100 --> 00:37:33,900
It's not like

787
00:37:35,900 --> 00:37:40,800
So the interesting thing about ANS was, you know, some years later

788
00:37:43,300 --> 00:37:50,000
young Colette started looking into implementing his own.

789
00:37:50,100 --> 00:37:53,500
I believe that he kind of had the idea on his own, okay?

790
00:37:54,300 --> 00:37:57,000
It turned out to be an ANS implementation, oh, really?

791
00:37:57,900 --> 00:38:00,500
And the implementation was interesting.

792
00:38:00,500 --> 00:38:05,500
He was not aware of an S at the time, we'd have that

793
00:38:05,800 --> 00:38:06,900
Okay, so nobody knows.

794
00:38:06,900 --> 00:38:07,100
All right.

795
00:38:07,100 --> 00:38:11,100
But my understanding is that he was fooling around with ideas on his

796
00:38:11,100 --> 00:38:16,300
own, he had some problems with his ideas and read the ANS paper and

797
00:38:16,300 --> 00:38:18,200
realized that it was the same.

798
00:38:18,600 --> 00:38:21,700
Basic idea isn't like this paper solves his problems that it's the

799
00:38:21,700 --> 00:38:24,400
same idea and it actually has the answer, okay?

800
00:38:26,300 --> 00:38:30,300
So, his implementation of ANS showed that it was quite interesting.

801
00:38:30,500 --> 00:38:31,000
Okay?

802
00:38:31,300 --> 00:38:34,000
And then, we started looking into it more like, yeah, that's actually

803
00:38:34,000 --> 00:38:35,100
is very interesting.

804
00:38:35,100 --> 00:38:41,200
Okay, because when you express ANS in terms of machine operations,

805
00:38:41,200 --> 00:38:43,000
they turn out to be quite appealing.

806
00:38:43,500 --> 00:38:44,100
I see.

807
00:38:44,200 --> 00:38:44,700
Okay.

808
00:38:44,800 --> 00:38:48,700
And this is just an artifact of how the ANS math works out.

809
00:38:49,100 --> 00:38:53,700
Is that when it maps on to actual instructions, it maps on better.

810
00:38:54,800 --> 00:38:56,500
Yeah, in arithmetic, right?

811
00:38:57,000 --> 00:38:59,500
It's actually it's very similar to Earth Metal Coating.

812
00:38:59,600 --> 00:38:59,800
Okay?

813
00:39:00,500 --> 00:39:04,700
There's a something I touch on and my blog, a tiny bit.

814
00:39:04,900 --> 00:39:09,300
I didn't really go into it in a great way, but ANS is, is very similar

815
00:39:09,300 --> 00:39:10,600
to The Backwards arithmetic.

816
00:39:10,600 --> 00:39:14,100
Coders are trashed the original way of doing arithmetic coding, okay?

817
00:39:14,100 --> 00:39:16,900
That's why ANS streams are process backwards.

818
00:39:16,900 --> 00:39:21,500
Got it and why you wrote on the Blackboard backwards, protect my

819
00:39:21,500 --> 00:39:21,700
right?

820
00:39:22,200 --> 00:39:22,600
Yeah.

821
00:39:23,400 --> 00:39:25,600
So ans is a lifo, coder.

822
00:39:25,800 --> 00:39:29,000
Got it and it the way it.

823
00:39:29,500 --> 00:39:29,900
It's

824
00:39:30,000 --> 00:39:34,500
loading up the probability in this way for a multi, simple sequence

825
00:39:36,300 --> 00:39:38,800
and the way it flushes out

826
00:39:40,700 --> 00:39:43,500
Incrementally in order to stay in finite Precision.

827
00:39:43,600 --> 00:39:46,900
Yeah, it's kind of backwards from the way arithmetic.

828
00:39:46,900 --> 00:39:47,800
Coders, do it.

829
00:39:47,800 --> 00:39:48,300
Okay.

830
00:39:49,100 --> 00:39:52,500
It flushes out the bottom bits instead of the top B.

831
00:39:52,500 --> 00:39:52,900
Okay?

832
00:39:55,300 --> 00:40:00,000
And that kind of winds up being the magic of what makes it so

833
00:40:00,000 --> 00:40:03,500
interesting really okay.

834
00:40:03,500 --> 00:40:07,800
So the fact that it flushes out bits from the other side of the value

835
00:40:08,100 --> 00:40:12,900
turns out to be that important in authoring the compressor that you

836
00:40:12,900 --> 00:40:13,600
can get.

837
00:40:13,700 --> 00:40:16,600
Oh I guess I should say decompressor since that's usually what you

838
00:40:16,600 --> 00:40:20,300
care about I suppose as decompression speed at least for rad style

839
00:40:20,300 --> 00:40:20,600
stuff.

840
00:40:20,600 --> 00:40:24,700
Yeah that one aspect of it turns out

841
00:40:24,800 --> 00:40:25,600
About important.

842
00:40:26,400 --> 00:40:27,100
Interesting.

843
00:40:27,600 --> 00:40:30,500
Why is there a way you can explain why without too much detail?

844
00:40:30,500 --> 00:40:31,300
Or is it really like no?

845
00:40:31,300 --> 00:40:34,900
You gotta understand the whole thing or is there sort of like vague

846
00:40:34,900 --> 00:40:36,100
why you can give?

847
00:40:38,700 --> 00:40:41,000
Because at first blush, you wouldn't think right?

848
00:40:41,000 --> 00:40:43,000
If you just ask someone like, oh hey, yeah.

849
00:40:43,000 --> 00:40:46,300
You know, you had this thing and it was flushing out bottom B before,

850
00:40:46,300 --> 00:40:49,500
and now it's pushing out top bits, I don't know that they would

851
00:40:49,500 --> 00:40:53,800
immediately go like, Ah, that's that's clearly going to give me so

852
00:40:53,800 --> 00:40:55,700
many more options than I had before, right?

853
00:40:55,700 --> 00:40:56,700
And maybe that's

854
00:40:58,600 --> 00:41:05,500
I mean the key thing is that it allows you to know your

855
00:41:05,500 --> 00:41:07,000
renormalization interval.

856
00:41:07,100 --> 00:41:14,000
Its I mean, so the way we talk about doing this is renormalization and

857
00:41:14,000 --> 00:41:20,600
in arithmetic coding because that's fifo and you're you're sort of

858
00:41:20,600 --> 00:41:22,500
zooming in as you go.

859
00:41:23,300 --> 00:41:27,700
That Zoom factor is a variable, okay, which is what leads to you

860
00:41:27,700 --> 00:41:29,900
having to do a divide, okay?

861
00:41:30,300 --> 00:41:35,100
Whereas with ANS you're building up from the back, okay?

862
00:41:35,200 --> 00:41:37,500
And you're dropping bits out of the bottom, okay?

863
00:41:38,000 --> 00:41:42,500
Which allows you to get to a fixed

864
00:41:43,900 --> 00:41:47,400
Kind of code word size and stay there.

865
00:41:47,900 --> 00:41:51,700
Hmm, you so you don't have to do the Divide interesting.

866
00:41:51,700 --> 00:41:52,300
Okay.

867
00:41:52,500 --> 00:41:57,000
So in arithmetic, the window is narrowing over time and in rands it

868
00:41:57,000 --> 00:41:58,900
isn't the the intervals.

869
00:41:59,400 --> 00:41:59,800
Yeah.

870
00:42:00,100 --> 00:42:02,100
one way to think about rants is that your

871
00:42:04,000 --> 00:42:06,100
you're building up a large integer, okay?

872
00:42:07,400 --> 00:42:14,100
And the entropy coding comes from the fact that if the integer is

873
00:42:14,100 --> 00:42:15,700
shorter, you send fewer bits.

874
00:42:16,000 --> 00:42:16,300
Okay?

875
00:42:16,300 --> 00:42:19,400
So you're actually, you're building up this integer X, okay?

876
00:42:19,400 --> 00:42:21,600
And you wind up sending log 2 of x b.

877
00:42:21,900 --> 00:42:24,000
Okay, that's what grants does, okay?

878
00:42:25,200 --> 00:42:32,800
So in reims the more probable symbols make X grow less.

879
00:42:33,100 --> 00:42:36,200
I love this probable symbols make it grow more.

880
00:42:36,300 --> 00:42:40,600
I see so you know as you're adding more probable symbols your integer

881
00:42:40,600 --> 00:42:44,800
is growing small amounts actually whenever you add a less probable

882
00:42:44,800 --> 00:42:46,900
symbol, it takes a bigger step, got it.

883
00:42:47,500 --> 00:42:52,600
So if you didn't do any streaming out, you would just be building up

884
00:42:52,600 --> 00:42:53,400
this large integer.

885
00:42:53,400 --> 00:42:54,400
You get to the end.

886
00:42:54,400 --> 00:42:54,800
You see.

887
00:42:54,800 --> 00:43:00,000
It's log 2x B, and you send it, got it and that is in ANS coder with

888
00:43:00,000 --> 00:43:00,500
got it.

889
00:43:00,500 --> 00:43:01,300
No flushing.

890
00:43:01,300 --> 00:43:01,800
Okay,

891
00:43:02,900 --> 00:43:07,100
What the Practical streaming ones do is build X up to 32 bits or

892
00:43:07,100 --> 00:43:11,800
something and then flush out bottom B at 8 or 16 or something.

893
00:43:11,800 --> 00:43:14,100
Yeah like this and then start adding more bits in.

894
00:43:14,400 --> 00:43:14,700
Yeah.

895
00:43:16,200 --> 00:43:17,600
I see ends.

896
00:43:18,000 --> 00:43:20,700
This is probably too detailed to ask, but I'm just going to ask it

897
00:43:20,700 --> 00:43:20,900
anyway.

898
00:43:20,900 --> 00:43:26,500
Then you can just say like ignore it for now, if you're building up an

899
00:43:26,500 --> 00:43:31,300
integer, you're actually building it up in bit order though.

900
00:43:31,300 --> 00:43:34,600
So, meaning, you're not adding to the, you're not incrementing the

901
00:43:34,600 --> 00:43:37,600
integer, this giant inter, you're not really incrementing it, you're

902
00:43:37,600 --> 00:43:39,400
actually concatenating B on to it.

903
00:43:39,400 --> 00:43:43,200
Meaning, you know, the low order, bits of the integer right away.

904
00:43:43,500 --> 00:43:44,800
Then how are you flushing?

905
00:43:44,800 --> 00:43:45,800
Does that make sense?

906
00:43:47,000 --> 00:43:48,100
Is that a dumb question?

907
00:43:51,000 --> 00:43:51,500
Okay.

908
00:43:52,800 --> 00:43:53,400
All right.

909
00:43:54,700 --> 00:43:59,200
The I mean so that is the key to the ANS streaming.

910
00:43:59,600 --> 00:44:00,200
Okay?

911
00:44:00,400 --> 00:44:05,200
So when you do streaming ANS, you don't make the same final number

912
00:44:05,200 --> 00:44:09,000
that you would if you didn't stream, okay?

913
00:44:10,300 --> 00:44:14,900
And the only reason it works is because I mean, so you're right.

914
00:44:15,900 --> 00:44:19,500
You are actually like multiplying this integer up and adding to it.

915
00:44:19,500 --> 00:44:19,900
That's it.

916
00:44:19,900 --> 00:44:22,800
So that's what it sounded like you were saying, but on a b, should

917
00:44:22,800 --> 00:44:24,100
change all these things.

918
00:44:27,100 --> 00:44:32,600
But the way the streaming scheme works and it is when you hit the

919
00:44:32,600 --> 00:44:37,000
streaming threshold, you just output them anyway because you assume

920
00:44:37,100 --> 00:44:42,500
look, the decompressor doesn't need the bits of the final integer.

921
00:44:42,700 --> 00:44:45,300
It just needs the bits of where I was.

922
00:44:45,500 --> 00:44:47,800
At this point in the final integer.

923
00:44:47,900 --> 00:44:52,500
So as long as I give it that it knows where I it was and it's just

924
00:44:52,500 --> 00:44:55,600
going to do the same thing to get to that final integer that I was

925
00:44:55,600 --> 00:44:57,300
doing that kind of exactly.

926
00:44:57,300 --> 00:44:59,800
So that is the key - streaming is

927
00:45:00,700 --> 00:45:04,800
The encoder decoder have to be in lockstep in the sense that they have

928
00:45:04,800 --> 00:45:07,100
to stream in in the exact same spot.

929
00:45:07,200 --> 00:45:07,700
Okay.

930
00:45:08,100 --> 00:45:09,700
And that's actually something that we

931
00:45:10,800 --> 00:45:13,500
There's some careful analysis that has to be done to make sure that

932
00:45:13,500 --> 00:45:16,200
the encoder and decoder can do so well.

933
00:45:16,200 --> 00:45:16,800
They have to

934
00:45:18,100 --> 00:45:18,400
Right.

935
00:45:18,400 --> 00:45:22,400
They, I mean they have to have enough information to know to do so in

936
00:45:22,400 --> 00:45:25,500
the same place I say, without sending more bits, you don't want to

937
00:45:25,500 --> 00:45:29,000
send another bit that says like, hey buddy, do your recognition now.

938
00:45:29,000 --> 00:45:29,600
I see.

939
00:45:30,000 --> 00:45:34,800
So you have to ensure that you can tell from the code word value

940
00:45:35,400 --> 00:45:36,200
itself.

941
00:45:36,200 --> 00:45:37,700
I see when to do that.

942
00:45:37,700 --> 00:45:40,600
Got it and up the decoder will be able to replicate what the end but

943
00:45:40,600 --> 00:45:41,400
they did.

944
00:45:41,400 --> 00:45:42,000
Exactly.

945
00:45:42,400 --> 00:45:45,100
And as out to be a specific condition,

946
00:45:46,200 --> 00:45:50,500
Which is interesting that's part of the theory of learning.

947
00:45:50,500 --> 00:45:54,800
ANS is exactly how that ends up being chosen or done great.

948
00:45:54,800 --> 00:45:58,900
It becomes a constraint actually on the on the way you do it on the

949
00:45:58,900 --> 00:46:01,200
way you build your code, word table.

950
00:46:01,900 --> 00:46:04,900
So one other I guess question while we're on that subject is that was

951
00:46:04,900 --> 00:46:06,000
actually that's a new thing.

952
00:46:06,000 --> 00:46:08,900
But kind of an interesting difference between ANS and arithmetic is

953
00:46:08,900 --> 00:46:12,500
that with most arithmetic schemes.

954
00:46:13,400 --> 00:46:18,300
What you're trying to do is approximate this imaginary infinite.

955
00:46:18,300 --> 00:46:21,800
Precision thing that you would get you know, if you did arithmetic

956
00:46:21,800 --> 00:46:24,200
coding on the whole file and never flush it out.

957
00:46:24,300 --> 00:46:24,600
Yes.

958
00:46:24,600 --> 00:46:26,500
Eventually you get some fractional thing.

959
00:46:26,500 --> 00:46:28,800
You have with output that got it perfectly.

960
00:46:28,900 --> 00:46:33,300
Yes, and the streaming methods are just trying to approximate that got

961
00:46:33,300 --> 00:46:33,700
it.

962
00:46:33,900 --> 00:46:38,200
And they generally don't put a constraint on how the decoder, does it

963
00:46:38,200 --> 00:46:42,400
streaming, okay, the decoder could stream in b, or B, so it doesn't

964
00:46:42,400 --> 00:46:43,000
matter who it is.

965
00:46:43,200 --> 00:46:44,300
You time got it.

966
00:46:46,000 --> 00:46:52,800
So that's a kind of that's a big difference to a NS which turns out to

967
00:46:52,800 --> 00:46:55,100
make a big difference in how you can implement it.

968
00:46:55,600 --> 00:46:59,100
And if I could ask one more question, I guess they're just sort of

969
00:46:59,100 --> 00:47:00,100
perspective question.

970
00:47:01,600 --> 00:47:04,800
What is the because I assume that it's related to all that if it's not

971
00:47:04,800 --> 00:47:08,200
too hard to give a little bit of insight into, why do?

972
00:47:08,200 --> 00:47:10,700
Because I've actually seen a mess compressor before.

973
00:47:10,900 --> 00:47:15,700
Why does the encoder and the decoder run opposite each other?

974
00:47:15,900 --> 00:47:19,600
In Direction, meaning in an ANS coder.

975
00:47:19,700 --> 00:47:23,100
Unlike and when I seen arithmetic, typically, the way that they're

976
00:47:23,100 --> 00:47:28,600
implemented these days is you put the, like you said, it's fifo both

977
00:47:28,600 --> 00:47:28,900
ways.

978
00:47:28,900 --> 00:47:32,600
It's like, I put in a bit stream, into the encoder it outputs that bit

979
00:47:32,600 --> 00:47:38,100
stream in order just smaller and then in the decoder, in comes the

980
00:47:38,100 --> 00:47:43,100
same bit stream and it comes out in order now decompressed, but ANS

981
00:47:43,100 --> 00:47:44,200
goes the other way around.

982
00:47:44,300 --> 00:47:45,700
I take a bit stream.

983
00:47:45,800 --> 00:47:49,300
And if I put it in an order and then decompress it, I'd get the

984
00:47:49,300 --> 00:47:51,600
flipped version of it.

985
00:47:51,700 --> 00:47:55,700
And so, when I see a NS encoders, they typically have the encoder run

986
00:47:55,700 --> 00:47:57,200
backwards through the stream.

987
00:47:57,200 --> 00:47:59,800
So that when the decoder decodes, it it comes out in the

988
00:48:00,200 --> 00:48:03,000
Order, where does that flipping come from?

989
00:48:03,000 --> 00:48:07,000
Is there an easy way to sort of think about how that is happening?

990
00:48:07,000 --> 00:48:10,100
Or does that require understanding ANS really deeply to have any idea?

991
00:48:10,100 --> 00:48:13,100
What comes from this streaming mechanism?

992
00:48:13,300 --> 00:48:17,800
We can use the space if you hold down the spacebar, you can just drag

993
00:48:17,800 --> 00:48:18,600
and pan around

994
00:48:20,900 --> 00:48:24,900
I mean, so if I'm trying to send my ABCD stream

995
00:48:26,300 --> 00:48:32,400
The way NS works is you get your first symbol and this goes into your

996
00:48:32,400 --> 00:48:33,200
accumulator.

997
00:48:33,400 --> 00:48:33,800
Okay.

998
00:48:34,500 --> 00:48:41,100
Then I get my next symbol and I you know, X does something is scaled

999
00:48:41,100 --> 00:48:43,500
up and then I add on something, okay?

1000
00:48:44,100 --> 00:48:46,800
And then let's say it's time to flush out.

1001
00:48:47,000 --> 00:48:49,100
Okay, so I drop some bits out of X.

1002
00:48:49,100 --> 00:48:50,900
Okay, they go out to the Stream.

1003
00:48:53,600 --> 00:48:54,300
I'm down here.

1004
00:48:54,400 --> 00:49:01,400
Now, X is reduced, and when that has happened, my new X has lost

1005
00:49:01,400 --> 00:49:03,000
information about C and D.

1006
00:49:03,400 --> 00:49:05,700
Okay, I can no longer decode C and D.

1007
00:49:05,800 --> 00:49:06,400
Okay.

1008
00:49:07,800 --> 00:49:10,500
So then I put be in and I do the same thing.

1009
00:49:10,500 --> 00:49:15,400
It's scale to up and add something in and maybe ice cream out again.

1010
00:49:17,700 --> 00:49:19,300
And now I can't decode be anymore.

1011
00:49:19,800 --> 00:49:25,400
Then I put a in 2x, I scale it up and add something at this point from

1012
00:49:25,400 --> 00:49:26,200
my ex.

1013
00:49:29,400 --> 00:49:30,500
I can only decode a

1014
00:49:33,800 --> 00:49:37,400
therefore, I have to go backwards with how the decoder went, okay?

1015
00:49:37,400 --> 00:49:41,000
Because I've streamed out the information from the end of the file

1016
00:49:41,000 --> 00:49:47,700
already, you know, in my in my file are low bits of X that I had

1017
00:49:47,700 --> 00:49:48,200
before.

1018
00:49:48,400 --> 00:49:52,100
So what probably that one.

1019
00:49:54,100 --> 00:49:55,700
So if I'm going to decode

1020
00:49:56,700 --> 00:49:57,900
To decode.

1021
00:49:57,900 --> 00:50:00,600
So I put the final value of x in my stream.

1022
00:50:02,000 --> 00:50:02,800
So, did you code?

1023
00:50:02,800 --> 00:50:04,500
I need to take from the Stream.

1024
00:50:06,000 --> 00:50:07,400
and I can output a

1025
00:50:09,200 --> 00:50:11,700
because of that information was the only thing that was in the final

1026
00:50:11,700 --> 00:50:12,600
value of x.

1027
00:50:13,100 --> 00:50:15,200
And then I need to input some more bits.

1028
00:50:15,900 --> 00:50:19,000
So after I decode a, my ex changes.

1029
00:50:20,200 --> 00:50:21,200
And I'm going backwards.

1030
00:50:21,200 --> 00:50:24,200
Now, I need to stream in my ex changes again.

1031
00:50:24,200 --> 00:50:26,200
Now, I have enough information to help would be

1032
00:50:28,100 --> 00:50:29,800
And go backwards and I stream in again.

1033
00:50:29,800 --> 00:50:31,900
And I have enough information to Output C and D.

1034
00:50:32,300 --> 00:50:38,000
Well, I guess looking at that diagram, it certainly makes sense, but I

1035
00:50:38,000 --> 00:50:41,800
guess I might turn the question around and go shouldn't that have been

1036
00:50:41,800 --> 00:50:45,400
the case for all interpreting coders that were arithmetic, like

1037
00:50:45,500 --> 00:50:48,200
because with an arithmetic encoder, I would have thought the same

1038
00:50:48,200 --> 00:50:48,800
would be true.

1039
00:50:48,800 --> 00:50:52,400
I'm putting these symbols in and presumably when I flush.

1040
00:50:52,500 --> 00:50:57,600
I'm going to lose information about the earliest symbol that I encoded

1041
00:50:57,800 --> 00:50:58,000
it.

1042
00:50:58,000 --> 00:50:59,900
But why are they different in that?

1043
00:51:00,500 --> 00:51:03,900
Well, that's what I was trying to hint that in terms of flushing from

1044
00:51:03,900 --> 00:51:05,200
the top, or the bottom.

1045
00:51:05,300 --> 00:51:09,000
And it's that difference which bits get flushed, right?

1046
00:51:09,200 --> 00:51:09,500
I see.

1047
00:51:09,500 --> 00:51:12,300
So, if you're enter peeing, if your entropy encoder flushes bits from

1048
00:51:12,300 --> 00:51:16,500
the top, it can be in order, both directions but if it flashes from

1049
00:51:16,500 --> 00:51:19,900
the bottom, it's going to have to run reverse.

1050
00:51:20,000 --> 00:51:21,700
So the that be a fair statement.

1051
00:51:21,700 --> 00:51:25,100
Yeah we'll just do a classic arithmetic code or real quick.

1052
00:51:25,100 --> 00:51:26,200
So you see the difference?

1053
00:51:27,600 --> 00:51:32,400
So classic way of thinking about arithmetic, coders is, you have your

1054
00:51:32,400 --> 00:51:33,300
number stream.

1055
00:51:34,000 --> 00:51:35,400
It's so hard to write on this thing.

1056
00:51:35,700 --> 00:51:37,600
Sorry, 0 & 1.

1057
00:51:37,900 --> 00:51:38,700
I'm not used to it.

1058
00:51:39,300 --> 00:51:41,500
You can hold it like a, like a pen pen.

1059
00:51:41,500 --> 00:51:42,400
Just you can.

1060
00:51:42,400 --> 00:51:43,600
Yeah, yeah.

1061
00:51:44,600 --> 00:51:49,500
So your your you have your thing between 0 and 1 you have probability

1062
00:51:49,500 --> 00:51:53,000
intervals for let's do binary.

1063
00:51:53,700 --> 00:51:57,300
So you have a simple 0 and a simple one with different probabilities.

1064
00:51:57,400 --> 00:51:58,200
The intervals.

1065
00:51:58,900 --> 00:52:05,200
As you code each one, you shrink your full range to that interval.

1066
00:52:05,400 --> 00:52:09,600
So you started from zero to one and you shrink to this range, okay?

1067
00:52:09,800 --> 00:52:13,900
So we drink to that range and then now we're subdividing with in here

1068
00:52:13,900 --> 00:52:17,100
as if this was your to 10K, the renormalization step.

1069
00:52:17,200 --> 00:52:17,700
I see.

1070
00:52:17,900 --> 00:52:20,400
So then we say we coded 0 B.

1071
00:52:20,400 --> 00:52:22,000
Now we're shrinking to this range.

1072
00:52:24,300 --> 00:52:28,200
And you keep going this gets smaller and smaller which is why you need

1073
00:52:28,200 --> 00:52:29,900
infinite Precision, gotcha.

1074
00:52:30,000 --> 00:52:34,100
And eventually, if you could do all your bits in your file, you wind

1075
00:52:34,100 --> 00:52:38,500
up with an infinite Precision number, you know, somewhere out here.

1076
00:52:38,900 --> 00:52:39,300
Gotcha.

1077
00:52:39,300 --> 00:52:42,600
That is you know, very finely specified.

1078
00:52:43,000 --> 00:52:43,500
Gotcha.

1079
00:52:44,100 --> 00:52:47,700
And this is sort of the, the, the anecdotal version is the like, hey,

1080
00:52:47,700 --> 00:52:53,200
you can encode all the data in in the world on like a metal bar, just

1081
00:52:53,300 --> 00:52:56,400
By picking the right distance along the metal bar and making a mark

1082
00:52:56,400 --> 00:52:57,700
like precisely there.

1083
00:52:57,800 --> 00:52:59,000
As long as you didn't need.

1084
00:52:59,000 --> 00:53:03,500
More than molecular Precision, you could encode, you know the Library

1085
00:53:03,500 --> 00:53:04,600
of Congress or something.

1086
00:53:04,600 --> 00:53:05,000
Sure.

1087
00:53:05,000 --> 00:53:06,400
This is that process, right?

1088
00:53:06,400 --> 00:53:07,900
You subdividing, ranges, yeah.

1089
00:53:09,000 --> 00:53:12,300
So in order to specify the spinal number

1090
00:53:13,200 --> 00:53:18,700
If you didn't know the length of the file, you would have to specify

1091
00:53:18,700 --> 00:53:22,000
it with infinite number infinite Precision, okay?

1092
00:53:22,100 --> 00:53:22,500
Okay?

1093
00:53:22,600 --> 00:53:23,100
Gotcha.

1094
00:53:23,100 --> 00:53:24,800
Which obviously you don't want to do right?

1095
00:53:25,200 --> 00:53:28,600
Since you do know the file, you know, where, you know, the length of

1096
00:53:28,600 --> 00:53:34,200
the file, you know, closest possible to sides of, you know, the

1097
00:53:34,200 --> 00:53:38,200
bracket of anywhere in between here and here would give me this file

1098
00:53:38,200 --> 00:53:41,300
because everything else is past the end of the file, right?

1099
00:53:41,300 --> 00:53:41,600
Got it.

1100
00:53:41,700 --> 00:53:42,200
Exactly.

1101
00:53:42,600 --> 00:53:42,900
So you

1102
00:53:43,000 --> 00:53:44,600
No, the two Clauses neighbors.

1103
00:53:44,600 --> 00:53:50,100
So you only have to specify enough bits of precision to differentiate

1104
00:53:50,400 --> 00:53:54,200
your final stream from to that level of detail, right?

1105
00:53:54,300 --> 00:53:59,800
Got it that winds up giving you the length of your code.

1106
00:54:00,400 --> 00:54:01,000
Got it.

1107
00:54:01,900 --> 00:54:07,700
And the way to do this incrementally streaming is as soon as you let's

1108
00:54:07,700 --> 00:54:09,200
see, my mid area.

1109
00:54:09,300 --> 00:54:11,000
My 0.5 is here.

1110
00:54:12,300 --> 00:54:14,700
My initial probabilities were not in the middle.

1111
00:54:15,500 --> 00:54:19,600
So as soon as your coded word,

1112
00:54:21,000 --> 00:54:25,700
Goes to either your whole interval has to go to either side of this

1113
00:54:25,700 --> 00:54:30,900
bit then you know that so let's call it this point.

1114
00:54:31,500 --> 00:54:35,300
I high goes or Milo goes over point five.

1115
00:54:37,300 --> 00:54:41,300
I know that my first bit in this final sequence will be one.

1116
00:54:42,200 --> 00:54:45,000
That means I can output a 1 B immediately.

1117
00:54:45,000 --> 00:54:45,700
Okay.

1118
00:54:45,800 --> 00:54:49,200
And it will never change, no matter what I code in the future.

1119
00:54:49,300 --> 00:54:49,900
Okay.

1120
00:54:50,300 --> 00:54:51,000
All right.

1121
00:54:51,200 --> 00:54:56,200
So now I see, I've output my one bit and then I can renormalize onto

1122
00:54:56,200 --> 00:54:59,200
this interval and grow this up to 01.

1123
00:54:59,200 --> 00:55:02,400
I get it now and you do that over and over.

1124
00:55:02,600 --> 00:55:06,000
So at this point, I could also output 0.

1125
00:55:06,400 --> 00:55:11,100
Another 0 a few times actually, okay.

1126
00:55:11,400 --> 00:55:11,900
I see.

1127
00:55:12,000 --> 00:55:16,100
Actually outputting the same bits as you would for infinite infinite

1128
00:55:16,100 --> 00:55:19,500
Precision, but you can do them yes.

1129
00:55:19,500 --> 00:55:20,800
From the top down.

1130
00:55:21,300 --> 00:55:23,700
Once, you know that you will be within that.

1131
00:55:24,900 --> 00:55:30,500
Interval got it and we're ignoring the middle under flow zone for this

1132
00:55:30,500 --> 00:55:31,300
discussion.

1133
00:55:31,300 --> 00:55:31,500
Okay?

1134
00:55:31,500 --> 00:55:32,700
Yeah, yes, yeah.

1135
00:55:32,700 --> 00:55:37,200
One of the Practical issues that you have to deal with, okay, so let

1136
00:55:37,200 --> 00:55:38,300
me ask one more question on that.

1137
00:55:38,300 --> 00:55:39,300
Is this too many questions?

1138
00:55:39,300 --> 00:55:39,900
How you doing?

1139
00:55:40,200 --> 00:55:40,600
Sorry.

1140
00:55:40,900 --> 00:55:41,600
Okay, good, good.

1141
00:55:43,000 --> 00:55:45,700
Let me ask one more question there because something interesting that

1142
00:55:45,700 --> 00:55:48,600
I kind of wanted to ask about along those lines.

1143
00:55:50,100 --> 00:55:58,400
So because based on what we talked about before with ANS encoder like

1144
00:55:58,400 --> 00:56:02,800
you were saying it's not necessary to actually output the bits of the

1145
00:56:03,000 --> 00:56:06,700
number that we're actually building.

1146
00:56:06,700 --> 00:56:08,900
So that large integer, that is the integer.

1147
00:56:08,900 --> 00:56:10,200
That's actually how we are encoding.

1148
00:56:10,200 --> 00:56:13,300
The stream theoretically is not what we actually output.

1149
00:56:13,300 --> 00:56:17,300
That number is being built, but the thing we output is actually an

1150
00:56:17,300 --> 00:56:18,100
intermediate.

1151
00:56:18,100 --> 00:56:19,700
A portion of the intermediate

1152
00:56:19,900 --> 00:56:22,400
Value that we were using to construct that number.

1153
00:56:22,400 --> 00:56:25,400
So it's like a step in the summation up to that number or

1154
00:56:25,400 --> 00:56:26,500
multiplication of their whatever.

1155
00:56:26,500 --> 00:56:30,300
The ANS fundamental equation is or whatever.

1156
00:56:33,000 --> 00:56:35,900
Why do I have to flush out of the bottom then?

1157
00:56:36,000 --> 00:56:42,800
Because if all I'm trying to do is tell the decoder, clue about what

1158
00:56:42,800 --> 00:56:48,400
the state was, what makes the low bits of my interim solution, so much

1159
00:56:48,400 --> 00:56:52,800
more interesting to flush than the high B, is that to minutiae to go

1160
00:56:52,800 --> 00:56:55,500
into, or is there an easy way to sort of mention?

1161
00:56:55,500 --> 00:56:56,700
How why?

1162
00:56:56,700 --> 00:56:59,000
That turns out to be the important.

1163
00:56:59,000 --> 00:56:59,800
There's an easy way.

1164
00:57:00,000 --> 00:57:00,700
Talk about that.

1165
00:57:01,600 --> 00:57:09,100
So your goal with ANS is to get the growth of your number X correctly,

1166
00:57:09,900 --> 00:57:10,300
okay?

1167
00:57:11,400 --> 00:57:18,000
So because the size of X is, you know, what gives you log 2 of X,

1168
00:57:18,000 --> 00:57:18,400
right?

1169
00:57:18,400 --> 00:57:20,500
You the length of your stream, which is what we wanted.

1170
00:57:20,500 --> 00:57:24,700
So your goal of your entropy code or is to make that length, be what

1171
00:57:24,700 --> 00:57:26,500
it should be theoretically right?

1172
00:57:26,500 --> 00:57:29,000
You know it should match the probability model.

1173
00:57:29,100 --> 00:57:29,600
Okay.

1174
00:57:30,600 --> 00:57:34,500
To be used is close to an optimal entry coder as possible.

1175
00:57:34,600 --> 00:57:35,100
Got it.

1176
00:57:35,500 --> 00:57:40,200
So the goal with a NS is to make the growth of X as close to that as

1177
00:57:40,200 --> 00:57:41,100
possible, right?

1178
00:57:41,100 --> 00:57:44,400
And the growth of X in this case means for the symbol table, every

1179
00:57:44,400 --> 00:57:48,200
symbol was supposed to be assigned, a very specific way in which X

1180
00:57:48,200 --> 00:57:48,900
would grow.

1181
00:57:49,400 --> 00:57:53,300
And we want to be as close as possible to that growth in order to hit

1182
00:57:53,300 --> 00:57:53,800
our Target.

1183
00:57:53,800 --> 00:57:56,900
Any error in that growth and our encoder gets worse.

1184
00:57:57,000 --> 00:57:57,800
Wait, yeah.

1185
00:57:58,400 --> 00:57:59,900
So when you stream,

1186
00:58:00,000 --> 00:58:04,700
Mount of X you're making the final value of x slightly wrong.

1187
00:58:06,000 --> 00:58:12,200
Okay, you want to do that in a way that minimizes the damage 0x grow,

1188
00:58:12,200 --> 00:58:15,600
and of course, the lower bits are the least relevant rate.

1189
00:58:16,000 --> 00:58:17,000
Exactly got it.

1190
00:58:17,300 --> 00:58:23,600
And so that turns out to be a factor in how precise your coder is.

1191
00:58:23,900 --> 00:58:24,400
Got it.

1192
00:58:24,600 --> 00:58:29,500
So free like four-speed frequently, we want to do B wise

1193
00:58:30,900 --> 00:58:33,800
renormalization, or b y streaming, which means we're putting out eight

1194
00:58:33,800 --> 00:58:34,600
bits at a time.

1195
00:58:34,700 --> 00:58:35,200
Got it.

1196
00:58:36,800 --> 00:58:39,600
And the more bits you strain out of there.

1197
00:58:40,100 --> 00:58:44,300
The more you are screwing up, the value of x.

1198
00:58:44,300 --> 00:58:45,700
We got it, we got it.

1199
00:58:47,300 --> 00:58:50,800
And, in some cases, we've even looked at doing word word at a time

1200
00:58:50,800 --> 00:58:55,500
output, which increases an even bigger cost, 16 bits of time rate is,

1201
00:58:55,500 --> 00:58:58,400
I believe Fabien posted a reference implementation of ANS.

1202
00:58:58,400 --> 00:58:59,600
That was 16 bits of time?

1203
00:58:59,600 --> 00:59:02,400
In fact, that obviously, was not trying to be optimal in any way,

1204
00:59:02,400 --> 00:59:05,000
speed or space, but it was just kind of like, here's how I do it.

1205
00:59:05,000 --> 00:59:05,600
I think his wits

1206
00:59:05,700 --> 00:59:08,500
16, if I remember correctly into the 16th at a time when yeah.

1207
00:59:10,100 --> 00:59:14,500
And because, you know, your your value of x at that point is bigger

1208
00:59:14,500 --> 00:59:16,200
than 2 to 24.

1209
00:59:16,200 --> 00:59:19,600
It's the, it mean, you can Define your interval in different ways.

1210
00:59:19,600 --> 00:59:20,000
Yeah.

1211
00:59:20,200 --> 00:59:24,000
Typically we choose it to be between, you know, X is between to the 24

1212
00:59:24,000 --> 00:59:25,500
into the 32, okay?

1213
00:59:26,100 --> 00:59:27,800
And then you output 8 at the bottom.

1214
00:59:30,000 --> 00:59:38,200
Whether it's got plus 0, or plus, 255, added onto to the 24 turns out.

1215
00:59:38,200 --> 00:59:41,400
It's not a very large amount of the value God.

1216
00:59:41,400 --> 00:59:46,200
I so it doesn't cost you very much in terms of your coding efficiency,

1217
00:59:46,600 --> 00:59:47,200
got it.

1218
00:59:48,000 --> 00:59:50,800
Whereas, if you streamed out the high B, you're essentially destroying

1219
00:59:50,800 --> 00:59:52,700
the most important part of the data that time.

1220
00:59:52,700 --> 00:59:55,100
So, it would be like an awful encoder at this point, right?

1221
00:59:55,900 --> 00:59:56,800
That's very interesting.

1222
00:59:57,100 --> 00:59:57,400
Okay.

1223
00:59:58,500 --> 00:59:58,900
All right.

1224
00:59:58,900 --> 00:59:59,400
So

1225
01:00:00,800 --> 01:00:02,400
Did you do anything else you want to say about that for?

1226
01:00:02,400 --> 01:00:06,400
I asked, a sort of a separate stream of questions here, that all seem

1227
01:00:06,400 --> 01:00:09,700
pretty good to me from it with me in my head.

1228
01:00:09,700 --> 01:00:11,700
But yeah, it's good.

1229
01:00:12,600 --> 01:00:15,500
I have a question about sort of some of the things that was underlying

1230
01:00:15,500 --> 01:00:16,000
a lot of stuff.

1231
01:00:16,000 --> 01:00:17,400
We talked about that.

1232
01:00:17,400 --> 01:00:21,800
I don't think I really know necessarily why has asked about that.

1233
01:00:22,100 --> 01:00:26,700
So in my experience when I've used compression and this is more of as

1234
01:00:26,700 --> 01:00:29,400
a user of compression, not as somebody who actually knows anything

1235
01:00:29,400 --> 01:00:29,800
about it.

1236
01:00:30,000 --> 01:00:36,500
And is like implementing it incremental is rarely something.

1237
01:00:36,500 --> 01:00:37,700
I actually

1238
01:00:38,800 --> 01:00:41,500
Care about in any practical sense.

1239
01:00:41,700 --> 01:00:45,900
Meaning, you know, from the perspective of say game, like gaming

1240
01:00:45,900 --> 01:00:46,300
working on.

1241
01:00:46,300 --> 01:00:50,300
Now, the way that the assets system is structured is everything's

1242
01:00:50,300 --> 01:00:55,400
broken up into streamable chunks that I am only loading to manage

1243
01:00:55,400 --> 01:00:56,400
paging and stuff like that.

1244
01:00:56,400 --> 01:01:00,500
Anyway, so, both the encoder and the decoder always know, they're

1245
01:01:00,500 --> 01:01:04,800
working with some fairly small 256k at a time pieces, or something

1246
01:01:04,800 --> 01:01:05,300
like this.

1247
01:01:06,500 --> 01:01:10,700
So why is incremental so important?

1248
01:01:11,000 --> 01:01:13,700
Is it more about the getting compression localized?

1249
01:01:13,700 --> 01:01:16,100
Or is it like why do we even care about?

1250
01:01:16,100 --> 01:01:18,500
Like a lot of things are saying like incremental incremental, why

1251
01:01:18,500 --> 01:01:20,200
aren't compressor is generally written?

1252
01:01:20,200 --> 01:01:23,100
Just to assume that they get to see the whole stream and work from

1253
01:01:23,100 --> 01:01:23,500
there.

1254
01:01:25,000 --> 01:01:27,700
Am I missing something about that or do just something you want to say

1255
01:01:27,700 --> 01:01:27,900
about that?

1256
01:01:27,900 --> 01:01:32,100
Because that in my perspective, while I can understand why certain

1257
01:01:32,600 --> 01:01:35,900
live like, you know, this this streaming that we're doing here, maybe

1258
01:01:35,900 --> 01:01:36,100
you might

1259
01:01:36,300 --> 01:01:38,400
It was a long stream and you need to be incredibly whatever else.

1260
01:01:38,400 --> 01:01:42,700
But in practice, for gains streaming, in that sense, it's almost never

1261
01:01:42,700 --> 01:01:44,800
necessary and the usage of the encoder.

1262
01:01:44,800 --> 01:01:47,400
And the decoder could always have all the data if they wanted to.

1263
01:01:47,400 --> 01:01:50,200
It's really just not that big for the sizes that we tend to care

1264
01:01:50,200 --> 01:01:50,800
about.

1265
01:01:51,200 --> 01:01:52,400
Can you talk a little bit about that?

1266
01:01:52,400 --> 01:01:54,200
Just to maybe put it in perspective.

1267
01:01:55,300 --> 01:01:56,700
Yeah, there's a lot of issues there.

1268
01:01:58,600 --> 01:02:01,600
So one thing is, for entropy coders.

1269
01:02:01,600 --> 01:02:04,500
The reason that we look at incremental is partly because of the finite

1270
01:02:04,500 --> 01:02:05,500
Precision issue.

1271
01:02:06,200 --> 01:02:10,900
That you 32-bit words or whatever to work in, can't do that many

1272
01:02:10,900 --> 01:02:14,500
symbols and their got it with Precision so you have to do one at a

1273
01:02:14,500 --> 01:02:18,100
time so you have to have a streaming way of doing that.

1274
01:02:18,300 --> 01:02:24,100
So mostly that's to keep the computation time down because if you kept

1275
01:02:24,100 --> 01:02:26,700
allowing it to grow and grow you would have to do like a big mum sort

1276
01:02:26,700 --> 01:02:31,000
of thing where we're doing multiplication on, you know, 4,096-bit

1277
01:02:31,000 --> 01:02:33,200
integers and Beyond and stuff.

1278
01:02:35,600 --> 01:02:42,700
In terms of compressors in general, I would say, historically people

1279
01:02:42,700 --> 01:02:47,100
were very interested in incremental because they actually did

1280
01:02:47,100 --> 01:02:51,600
incremental compressors, okay, like back in the Shannon Bell Labs

1281
01:02:51,600 --> 01:02:52,400
days, right.

1282
01:02:52,400 --> 01:02:56,400
Okay, people actually wanted to be able to flush one bite at a time,

1283
01:02:56,400 --> 01:02:56,700
right?

1284
01:02:56,700 --> 01:02:58,500
Over a very slow channel, right?

1285
01:02:58,500 --> 01:02:59,800
Because they just had much

1286
01:03:00,200 --> 01:03:02,800
More severe, practical constraints that we do now.

1287
01:03:02,900 --> 01:03:03,300
Whatever?

1288
01:03:03,800 --> 01:03:06,500
I mean if you're doing a telegraph, yes, you actually.

1289
01:03:06,500 --> 01:03:10,100
Yes, you don't want to have a thousand symbols before you get

1290
01:03:10,100 --> 01:03:10,700
anything.

1291
01:03:10,700 --> 01:03:11,300
Got it.

1292
01:03:12,500 --> 01:03:14,700
Yeah, that's much less of a concern.

1293
01:03:14,700 --> 01:03:19,400
Now, like almost everybody is working on at least some kind of packet.

1294
01:03:19,400 --> 01:03:20,000
Yeah.

1295
01:03:21,700 --> 01:03:27,600
So there are I would say that people have moved towards looking into

1296
01:03:27,700 --> 01:03:29,800
block-wise compressors that

1297
01:03:30,000 --> 01:03:35,000
Don't work incrementally, got it or things like hierarchical grammars

1298
01:03:35,000 --> 01:03:39,300
and block sorting and things like that, that fundamentally our whole

1299
01:03:39,300 --> 01:03:40,500
file only.

1300
01:03:41,100 --> 01:03:43,500
Okay, so they just they start out with the assumptions.

1301
01:03:43,500 --> 01:03:46,700
Like look, we're just assuming we get to see everything and the point

1302
01:03:46,700 --> 01:03:49,500
of this compressor is to look at all the data first and make some

1303
01:03:49,500 --> 01:03:50,100
decisions.

1304
01:03:50,200 --> 01:03:55,900
Yeah, most compressors are still incremental

1305
01:03:57,700 --> 01:04:01,200
partly it's a practicality issue that

1306
01:04:04,000 --> 01:04:08,500
I mean, so there's a lot of factors there, like, even if you could do

1307
01:04:08,500 --> 01:04:15,200
whole file compression, you usually don't want to because you want

1308
01:04:15,400 --> 01:04:16,400
adaptability.

1309
01:04:16,600 --> 01:04:20,600
You want your compressor to be able to change as it goes through.

1310
01:04:20,700 --> 01:04:21,100
Yes.

1311
01:04:21,400 --> 01:04:25,100
So, even if you had a whole file compressor which imagine for the

1312
01:04:25,100 --> 01:04:28,400
moment, yes, say you have a blocks order or something like that, okay?

1313
01:04:29,000 --> 01:04:30,700
In order for that to be optimal.

1314
01:04:31,400 --> 01:04:35,900
You would want to find regions of the vial to cut.

1315
01:04:36,900 --> 01:04:37,200
Right.

1316
01:04:37,200 --> 01:04:41,800
Said that give you better compression by not doing whole file?

1317
01:04:42,000 --> 01:04:49,500
Yes, because real data is very changeable, you don't want to just make

1318
01:04:49,500 --> 01:04:53,200
a model for a whole file and apply it across the whole file, right?

1319
01:04:55,400 --> 01:04:59,800
So, by doing a streaming compressor, even if you don't care

1320
01:04:59,800 --> 01:05:04,900
necessarily about the streaming capability of it, it allows you to

1321
01:05:04,900 --> 01:05:09,800
make it, learn over time, and offer, get over time.

1322
01:05:09,800 --> 01:05:11,000
It's important, right?

1323
01:05:11,100 --> 01:05:16,400
So, basically, like, in some sense, the streaming is a relatively

1324
01:05:16,400 --> 01:05:22,100
efficient way to have localized statistics for your statistical model.

1325
01:05:22,100 --> 01:05:25,000
It's like it's, yeah, it's sort of only,

1326
01:05:25,200 --> 01:05:27,600
You had a narrow section of the file.

1327
01:05:27,600 --> 01:05:31,200
And since we assume that typically things in the file, tend to appear

1328
01:05:31,200 --> 01:05:34,200
close together, if they're similar, or something like this being

1329
01:05:34,200 --> 01:05:37,500
circumstances where that's true, this will do well because it won't be

1330
01:05:37,500 --> 01:05:40,400
trying to use statistics from very early in the file to compress

1331
01:05:40,400 --> 01:05:42,900
things late in the file when they are no longer applicable or things

1332
01:05:42,900 --> 01:05:43,500
like that, great.

1333
01:05:43,800 --> 01:05:46,200
I think it's also a good way to limit memory.

1334
01:05:46,200 --> 01:05:46,700
Use.

1335
01:05:47,200 --> 01:05:50,600
You know, if you only have four megabytes to put your model in

1336
01:05:50,700 --> 01:05:53,900
Project, you don't want to make a 4, MB memory for the model of the

1337
01:05:53,900 --> 01:05:54,700
whole file.

1338
01:05:55,100 --> 01:05:58,800
Cuz that is not very much Precision for the whole file got it.

1339
01:05:59,100 --> 01:05:59,700
You rather have a

1340
01:06:00,000 --> 01:06:05,400
MB model of a small region in scan that over, so that you actually

1341
01:06:05,400 --> 01:06:10,000
have kind of more bites of model memory per bite that you're trying to

1342
01:06:10,000 --> 01:06:11,500
work on, got it.

1343
01:06:12,800 --> 01:06:15,800
All right, two more things I wanted to ask if that's cool.

1344
01:06:17,600 --> 01:06:22,600
So I wanted to ask a question from theoretical perspective and kind of

1345
01:06:22,600 --> 01:06:23,500
touched on to it.

1346
01:06:27,000 --> 01:06:32,000
So the modern noodle compressors are not streaming back and mermaid,

1347
01:06:32,000 --> 01:06:32,800
and so on.

1348
01:06:33,300 --> 01:06:33,900
Oh, really?

1349
01:06:33,900 --> 01:06:34,300
Yeah.

1350
01:06:34,400 --> 01:06:34,900
Okay.

1351
01:06:34,900 --> 01:06:36,000
You want to talk a little bit about that?

1352
01:06:36,000 --> 01:06:37,600
I didn't know that.

1353
01:06:38,500 --> 01:06:40,500
So they are block based in a sense.

1354
01:06:40,500 --> 01:06:42,300
You give them your like, here's the chunk.

1355
01:06:43,500 --> 01:06:44,700
Yeah, they work on blocks.

1356
01:06:44,700 --> 01:06:45,200
Okay?

1357
01:06:46,200 --> 01:06:51,500
And part of that is just taking advantage of the efficiency of not

1358
01:06:51,500 --> 01:06:57,200
having to be streaming that you can kind of work on chunks of the

1359
01:06:57,200 --> 01:06:57,800
time.

1360
01:06:57,800 --> 01:06:58,200
Yeah.

1361
01:06:59,500 --> 01:07:05,800
Instead of having to necessarily do do one by one output okay and that

1362
01:07:05,800 --> 01:07:08,900
is for what purpose is that to achieve better compression or is that

1363
01:07:08,900 --> 01:07:11,900
for better efficiency like what was the speed?

1364
01:07:12,000 --> 01:07:12,300
It's forced.

1365
01:07:12,500 --> 01:07:12,900
Speed.

1366
01:07:13,000 --> 01:07:13,400
Okay.

1367
01:07:14,400 --> 01:07:16,800
Because that way, you can know, hey, this is how much I'm working on,

1368
01:07:16,800 --> 01:07:19,900
and I can look at it and make decisions about what would be the,

1369
01:07:19,900 --> 01:07:23,100
fastest, way, for the compressor operate here, or something like that

1370
01:07:23,100 --> 01:07:29,200
or Aids, it's about being able to reorganize how the output Loop works

1371
01:07:29,700 --> 01:07:34,700
because kindly, okay, the output Loop meaning just to be compressors.

1372
01:07:34,700 --> 01:07:39,300
Yeah, okay, so I mean the simplest way to think about it would be like

1373
01:07:41,600 --> 01:07:45,400
Say you're outputting, you're trying to Output some data and you have

1374
01:07:45,400 --> 01:07:49,000
a bit that tells you whether to Output an A or B.

1375
01:07:49,100 --> 01:07:53,100
Yes, if you're going streaming, you have to go through each bite of

1376
01:07:53,100 --> 01:07:55,400
your output and check that bit and go.

1377
01:07:55,400 --> 01:07:58,000
Okay, either I'll put an A or B got it.

1378
01:07:58,100 --> 01:08:01,400
So instead we're trying to reorganize so that we can do like let's

1379
01:08:01,400 --> 01:08:06,600
output a bunch of A's ahead and then we output a bunch of bees ahead.

1380
01:08:06,600 --> 01:08:07,100
Okay.

1381
01:08:08,200 --> 01:08:09,900
Oh oh.

1382
01:08:09,900 --> 01:08:10,300
Oh okay.

1383
01:08:10,400 --> 01:08:11,300
I think I see what you're saying here.

1384
01:08:11,300 --> 01:08:14,400
So basically you're saying it doesn't even necessarily right in order

1385
01:08:14,600 --> 01:08:19,800
so meaning it may go right in a six bytes away and then ready to be in

1386
01:08:20,800 --> 01:08:21,500
between.

1387
01:08:21,500 --> 01:08:22,000
Yeah.

1388
01:08:22,399 --> 01:08:23,800
Is that a correct statement of what you just said?

1389
01:08:23,800 --> 01:08:25,600
That's what I thought you just said but I wasn't sure.

1390
01:08:25,600 --> 01:08:27,899
I hope I'm not going to go into the details very much.

1391
01:08:28,000 --> 01:08:28,500
Okay.

1392
01:08:28,800 --> 01:08:33,500
All right, if we should probably move on but just mentioning this fair

1393
01:08:33,500 --> 01:08:34,000
enough.

1394
01:08:34,800 --> 01:08:40,200
Okay, so ignoring proprietary high-tech compression, let me ask this

1395
01:08:40,399 --> 01:08:43,800
Acrostic is because they did not involve anything you do specific.

1396
01:08:43,800 --> 01:08:44,100
Yeah.

1397
01:08:45,300 --> 01:08:50,800
So I sort of along the lines of what I asked earlier and this is

1398
01:08:50,800 --> 01:08:55,100
again, sort of more my curiosity about the subject matter from not

1399
01:08:55,200 --> 01:08:58,800
having ever had the time to sit down and really understand it myself.

1400
01:08:58,899 --> 01:08:59,700
I have like a bunch of

1401
01:09:00,000 --> 01:09:03,200
Like this is what I would look into if I had time to like try to build

1402
01:09:03,200 --> 01:09:07,200
up this knowledge so I try and try to cheat by asking you these

1403
01:09:07,200 --> 01:09:08,000
questions.

1404
01:09:08,100 --> 01:09:08,600
Yes.

1405
01:09:09,800 --> 01:09:10,399
So

1406
01:09:11,899 --> 01:09:18,300
when you look at something like an arithmetic encoder or maybe a

1407
01:09:18,300 --> 01:09:21,300
Huffman encoder and you look at something like l z,

1408
01:09:22,700 --> 01:09:27,000
So, one of the interesting things about these from the cursory

1409
01:09:27,000 --> 01:09:28,800
inspection is like an LZ.

1410
01:09:28,800 --> 01:09:31,200
Encoder is a fairly old encoder, right?

1411
01:09:31,200 --> 01:09:32,399
I mean, it's like 40 years old.

1412
01:09:32,399 --> 01:09:34,300
At this point, roughly right.

1413
01:09:35,000 --> 01:09:42,200
Lz77 was 1977 or something and it's like 2016 2017 now, right again.

1414
01:09:42,200 --> 01:09:46,399
So we're literally like 40 years away from the invention of thing.

1415
01:09:47,000 --> 01:09:49,899
Yet, the typical compressors that are used to compress.

1416
01:09:49,899 --> 01:09:52,399
Generic data are still these kinds.

1417
01:09:52,500 --> 01:09:56,700
Pressors like, you know, LZ n a, which is the most commonly used

1418
01:09:56,700 --> 01:10:00,500
high-compression variant, that I know of me as, um, a sari L DNA is

1419
01:10:00,500 --> 01:10:01,100
yours.

1420
01:10:01,400 --> 01:10:08,300
So lzma is still using variance on those algorithms from what I

1421
01:10:08,300 --> 01:10:08,900
understand.

1422
01:10:08,900 --> 01:10:09,400
She's right.

1423
01:10:11,100 --> 01:10:14,400
So I kind of had like a two-part question there.

1424
01:10:14,500 --> 01:10:15,900
The first question is

1425
01:10:17,400 --> 01:10:22,100
Is there some specific reason why we haven't moved past those

1426
01:10:22,100 --> 01:10:22,900
compressors?

1427
01:10:22,900 --> 01:10:26,300
Are they at a sweet spot in terms of being able to compress generic

1428
01:10:26,300 --> 01:10:26,500
data?

1429
01:10:26,500 --> 01:10:29,400
That is simply impossible to get by in any practical sense?

1430
01:10:29,400 --> 01:10:32,600
Meaning like in order to like make significant improvements on them,

1431
01:10:32,700 --> 01:10:35,700
you're going to end up in a position where you're doing a incredibly

1432
01:10:35,700 --> 01:10:39,800
large amount of work to get very little practical returning.

1433
01:10:39,800 --> 01:10:41,300
Like did they hit a curve particularly?

1434
01:10:41,300 --> 01:10:41,700
Well,

1435
01:10:42,600 --> 01:10:45,800
Or is it more the case of like we just don't know yet, we haven't been

1436
01:10:45,800 --> 01:10:48,300
able to make theoretical improvements here, that sort of thing.

1437
01:10:49,200 --> 01:10:52,100
That's my first kind of question about those, you know, Huffman

1438
01:10:52,100 --> 01:10:54,700
arithmetic LZ which seemed to kind of be in this.

1439
01:10:54,700 --> 01:10:58,000
Like we still use them today they're still the best whatever in terms

1440
01:10:58,000 --> 01:10:58,500
of like.

1441
01:10:58,800 --> 01:11:01,900
So, that's the first question and I have a second question which I'll

1442
01:11:01,900 --> 01:11:06,000
wait till after four, but those, that that's kind of the first one.

1443
01:11:06,000 --> 01:11:07,700
It's my second one is related.

1444
01:11:09,600 --> 01:11:12,200
I mean, the answer is just another good algorithm.

1445
01:11:13,200 --> 01:11:16,800
I mean, we still use good algorithms of all kinds.

1446
01:11:16,800 --> 01:11:20,300
Yeah we still use a star and okay whatever.

1447
01:11:21,300 --> 01:11:23,800
You know, we still use quicksort, okay?

1448
01:11:23,800 --> 01:11:27,200
Like when there's a good algorithm, that happens to be kind of a sweet

1449
01:11:27,200 --> 01:11:28,400
spot of implementation.

1450
01:11:28,400 --> 01:11:29,900
Yeah you're going to keep using it.

1451
01:11:29,900 --> 01:11:33,100
Okay and you modify it slightly over time, okay?

1452
01:11:34,200 --> 01:11:36,000
But you don't go to something else.

1453
01:11:36,000 --> 01:11:41,200
Unless there's a major discovery which could be I mean inventing, new

1454
01:11:41,200 --> 01:11:42,200
data compression, algorithms.

1455
01:11:42,400 --> 01:11:47,000
It is not like a science that you go and chip away at and they just

1456
01:11:47,000 --> 01:11:48,500
get better, don't panic.

1457
01:11:49,300 --> 01:11:54,800
You can always get more compression by throwing more work at it you

1458
01:11:54,800 --> 01:11:56,100
know by making the model better.

1459
01:11:56,100 --> 01:11:59,200
But refining there's you know,

1460
01:12:00,000 --> 01:12:04,600
You look at anything like lzma, there are every single spot where it

1461
01:12:04,600 --> 01:12:05,400
does coating.

1462
01:12:05,900 --> 01:12:08,800
You say, I could compress this better, okay?

1463
01:12:08,800 --> 01:12:10,400
But it would take more CPU work.

1464
01:12:10,600 --> 01:12:13,500
I see or more memory or something.

1465
01:12:14,000 --> 01:12:16,600
So then it's question of, is it worth it to throw that at that?

1466
01:12:17,000 --> 01:12:21,000
And in the answer, in that case, is almost always know, I guess, so

1467
01:12:21,000 --> 01:12:21,200
does.

1468
01:12:21,200 --> 01:12:24,000
It depends what what trade-off you want, man?

1469
01:12:24,300 --> 01:12:27,500
What your goal is, but there's no like magic.

1470
01:12:28,200 --> 01:12:34,300
So what happens with data compression is there's kind of obvious

1471
01:12:34,400 --> 01:12:36,000
vectors to work on things.

1472
01:12:36,000 --> 01:12:39,900
There's like you can you can take any existing algorithm and throw

1473
01:12:39,900 --> 01:12:42,600
other existing algorithms on it, you know, they compose

1474
01:12:44,100 --> 01:12:44,800
Very easily.

1475
01:12:44,900 --> 01:12:45,400
Okay?

1476
01:12:45,500 --> 01:12:50,900
So you can toss PP M into l z, okay, you know, you can you can take

1477
01:12:50,900 --> 01:12:53,700
something that does Huffman coding and replace it with her athletic

1478
01:12:53,700 --> 01:12:54,200
coating, right?

1479
01:12:54,200 --> 01:12:54,600
Okay.

1480
01:12:54,700 --> 01:12:58,200
So you can always modify these algorithms, you're not really

1481
01:12:58,200 --> 01:13:01,800
inventing, anything new but you're kind of bolting together a new

1482
01:13:01,800 --> 01:13:05,900
machine right out of the parts and you can trade off your speed versus

1483
01:13:05,900 --> 01:13:07,200
compression ratio that way.

1484
01:13:07,400 --> 01:13:10,400
Gotcha, but you aren't making a big step into

1485
01:13:11,600 --> 01:13:13,700
You know, unexplored territory.

1486
01:13:14,000 --> 01:13:16,600
Yes of efficiency got it.

1487
01:13:17,900 --> 01:13:23,100
So like is there a big step that would give us more compression at

1488
01:13:23,100 --> 01:13:24,200
most of the times, really?

1489
01:13:24,200 --> 01:13:24,800
Yeah.

1490
01:13:25,600 --> 01:13:26,200
We don't know.

1491
01:13:26,300 --> 01:13:26,700
Okay.

1492
01:13:26,700 --> 01:13:27,900
Like we haven't found it yet.

1493
01:13:27,900 --> 01:13:29,200
Are kind of maybe there is.

1494
01:13:29,300 --> 01:13:30,200
Maybe there isn't.

1495
01:13:30,200 --> 01:13:30,700
All right?

1496
01:13:30,900 --> 01:13:34,000
I mean it feels like there isn't.

1497
01:13:34,100 --> 01:13:36,600
There's nothing for me is because we should have seen it by now, every

1498
01:13:36,600 --> 01:13:36,800
well.

1499
01:13:36,800 --> 01:13:37,200
Okay.

1500
01:13:37,300 --> 01:13:40,600
But maybe you know, that's like with ANS came out of nowhere block,

1501
01:13:40,600 --> 01:13:41,800
sorting came out of nowhere.

1502
01:13:42,000 --> 01:13:46,800
When he's when these things do appear, they tend to be like, wow

1503
01:13:46,800 --> 01:13:47,800
unexpected, right?

1504
01:13:47,800 --> 01:13:48,200
Okay.

1505
01:13:48,200 --> 01:13:52,600
Because if it was something expected, someone would happen 40 already

1506
01:13:52,600 --> 01:13:55,000
rate because people are looking at this all the time,

1507
01:13:55,500 --> 01:13:58,800
Tends to be something weird that comes out of nowhere and I go.

1508
01:13:58,800 --> 01:14:03,500
Well, so maybe there, I mean, it doesn't seem like there's that much

1509
01:14:04,300 --> 01:14:05,300
fat left in it.

1510
01:14:05,300 --> 01:14:08,000
I mean, if you think about what you can express in terms of machine

1511
01:14:08,000 --> 01:14:11,600
instructions, yeah that makes it data compressor.

1512
01:14:11,700 --> 01:14:15,700
Yeah, it's hard to imagine where it is okay but you know who knows.

1513
01:14:15,900 --> 01:14:16,300
Yeah.

1514
01:14:16,900 --> 01:14:22,800
And the other factor is that as the hardware changes

1515
01:14:23,500 --> 01:14:26,500
The algorithms that work well on the hardware can change as well.

1516
01:14:26,600 --> 01:14:26,900
Right.

1517
01:14:27,000 --> 01:14:34,100
So the things that we're doing now are different design choices than

1518
01:14:34,100 --> 01:14:37,500
we would if we were making 20 years ago, just because the hardware is

1519
01:14:37,500 --> 01:14:38,300
different.

1520
01:14:38,300 --> 01:14:38,700
I suppose.

1521
01:14:38,700 --> 01:14:40,300
It's also true that in general.

1522
01:14:40,300 --> 01:14:43,000
The trade-offs are constantly changing in terms of what you even want

1523
01:14:43,000 --> 01:14:43,900
in terms of compression.

1524
01:14:43,900 --> 01:14:48,200
Because you know, nowadays there's a whole Suite of things that you

1525
01:14:48,200 --> 01:14:49,100
might not even care about.

1526
01:14:49,100 --> 01:14:52,900
I mean, you know, it used to be that compressing, your

1527
01:14:53,600 --> 01:14:57,600
CD collection to MP3 was like a really important thing that allowed

1528
01:14:57,600 --> 01:14:59,800
you to have that CD collection digitized at all.

1529
01:15:00,200 --> 01:15:05,000
Nowadays you really just don't care about 10x smaller CDs for your

1530
01:15:05,000 --> 01:15:07,900
like whatever, like I can store the whole thing uncompressed and don't

1531
01:15:07,900 --> 01:15:09,500
care so it's definitely true that.

1532
01:15:09,500 --> 01:15:13,000
Like what you're, you know, nowadays bandwidth is probably the more

1533
01:15:13,000 --> 01:15:15,400
important thing that people are trying to compress for things like

1534
01:15:15,400 --> 01:15:18,200
this and so you're looking at you know, more of those use cases.

1535
01:15:18,200 --> 01:15:21,300
So I suppose like what you actually want your compression to do and

1536
01:15:21,300 --> 01:15:24,800
why probably moves as well, which would change, totally what the

1537
01:15:24,800 --> 01:15:26,000
relevant thing is, right?

1538
01:15:26,000 --> 01:15:28,600
You know, the big thing that's happening.

1539
01:15:28,900 --> 01:15:29,800
I mean there's a lot of

1540
01:15:30,600 --> 01:15:33,700
Obviously like 4K video and things like that is a huge issue for

1541
01:15:33,700 --> 01:15:34,300
compression.

1542
01:15:34,700 --> 01:15:35,200
Yes.

1543
01:15:35,800 --> 01:15:40,000
The other big thing is the speed of disks with like nvram disks, and

1544
01:15:40,100 --> 01:15:41,200
yes, right, right.

1545
01:15:41,200 --> 01:15:46,400
It's like massively changed, so this idea of like using compression to

1546
01:15:46,400 --> 01:15:47,000
speed up.

1547
01:15:47,100 --> 01:15:48,900
I owe ya changed?

1548
01:15:48,900 --> 01:15:49,800
Yes, romantically.

1549
01:15:49,900 --> 01:15:54,700
Yes, because of that, except on consoles still, that's me.

1550
01:15:54,700 --> 01:15:58,600
Yes, someday someday we won't care about that anymore because we're

1551
01:15:58,600 --> 01:15:59,700
not quite there yet.

1552
01:16:01,400 --> 01:16:07,000
Okay, so last question that I had this is kind of a bit of a minutiae

1553
01:16:07,000 --> 01:16:09,900
question but it's still one of those ones that I feel like I'm just

1554
01:16:09,900 --> 01:16:13,100
curious about in the, like, I just don't have enough theoretical

1555
01:16:13,300 --> 01:16:16,000
understanding of a lot of the stuff to answer myself.

1556
01:16:17,300 --> 01:16:23,500
So from a Layman's perspective when you look at something like LZ,

1557
01:16:23,500 --> 01:16:27,000
Hoffman or something, like a sir, l z arithmetic as a way that people

1558
01:16:27,000 --> 01:16:28,400
would prevent a compressor.

1559
01:16:30,000 --> 01:16:35,000
One of the things that's kind of confusing about why it works the way

1560
01:16:35,000 --> 01:16:42,000
it does, is that it sort of seems like, for lack of a better term.

1561
01:16:42,300 --> 01:16:46,600
There's an arbitrary decision about what is a symbol?

1562
01:16:47,100 --> 01:16:49,400
Versus what is not a symbol.

1563
01:16:49,400 --> 01:16:53,800
And what I mean by that, is, if you take a look at like literature or

1564
01:16:53,800 --> 01:16:57,800
something like that, that talks about say arithmetic encoding.

1565
01:16:58,100 --> 01:17:01,300
It makes very simple understandable sense.

1566
01:17:01,300 --> 01:17:04,500
When you read it, it's like, let's suppose, we have this alphabet of

1567
01:17:04,500 --> 01:17:07,100
things, we're trying to encode, we don't care what they are.

1568
01:17:07,100 --> 01:17:08,800
You can make up whatever you want.

1569
01:17:09,100 --> 01:17:11,100
You can say how many symbols you want them, what they are.

1570
01:17:11,100 --> 01:17:13,600
And all we really care about is that you can assign a probability to

1571
01:17:13,600 --> 01:17:15,800
each one, and then that, that probability is accurate.

1572
01:17:16,200 --> 01:17:16,900
And then we make the

1573
01:17:17,000 --> 01:17:19,700
Ascertainment of Monaco turn off you go, that's a pretty easy thing to

1574
01:17:19,700 --> 01:17:20,400
understand.

1575
01:17:21,000 --> 01:17:24,600
When you extend the system out to something like an LZ encoder with an

1576
01:17:24,600 --> 01:17:25,900
arithmetic back end,

1577
01:17:27,100 --> 01:17:30,200
All of a sudden there's this sort of idea that like well, okay, so

1578
01:17:30,900 --> 01:17:35,600
what a symbol is in this case is the output of the things that the LZ

1579
01:17:35,600 --> 01:17:38,600
compressor cares about which means, you know, we've got symbols of the

1580
01:17:38,600 --> 01:17:39,100
form.

1581
01:17:39,100 --> 01:17:42,800
Say, there's a look back distance that I need some way of expressing

1582
01:17:42,800 --> 01:17:43,100
that.

1583
01:17:43,100 --> 01:17:45,500
So the symbols could be offsets of things.

1584
01:17:45,800 --> 01:17:48,300
I've got another thing which is symbols, which are I have to encode

1585
01:17:48,300 --> 01:17:51,500
literals, so in some sense I have symbols that would be the actual

1586
01:17:51,500 --> 01:17:51,900
symbols.

1587
01:17:51,900 --> 01:17:54,000
I would have talked about, if I just have the arithmetic encoder,

1588
01:17:54,000 --> 01:17:56,100
those are still involved there and so on, right?

1589
01:17:58,200 --> 01:17:59,800
And what's a little bit difficult?

1590
01:18:00,500 --> 01:18:01,800
And this is my question.

1591
01:18:01,900 --> 01:18:04,100
What's a little bit difficult to wrap one's head around.

1592
01:18:04,100 --> 01:18:06,200
I feel like is

1593
01:18:07,700 --> 01:18:12,700
It seems like these sorts of things are treating that very fast and

1594
01:18:12,700 --> 01:18:17,500
loose in some sense, it's not obvious to me why the theory doesn't

1595
01:18:17,500 --> 01:18:21,500
wrap the whole thing up in a more coherent way where you can talk

1596
01:18:21,500 --> 01:18:27,600
about symbols or maybe a better way to State, it would be an LZ system

1597
01:18:27,600 --> 01:18:32,500
is a system that has the ability to talk about symbols by using

1598
01:18:32,500 --> 01:18:35,000
previous symbols that you seemed to construct them.

1599
01:18:35,300 --> 01:18:37,300
But in arithmetic, encoder cannot do

1600
01:18:37,500 --> 01:18:38,200
Such a thing.

1601
01:18:39,100 --> 01:18:43,100
Why do we not have can encoders that talk about both of those things.

1602
01:18:43,100 --> 01:18:46,100
Theoretically, as the same operation, does that?

1603
01:18:46,500 --> 01:18:49,600
And I wish I could phrase the question better, but the question in and

1604
01:18:49,600 --> 01:18:53,700
of itself is about not really understanding how these two things

1605
01:18:53,700 --> 01:18:59,800
really fundamentally differ and why it's feels a little bit under

1606
01:18:59,800 --> 01:19:03,300
baked, in terms of the way that it's expressed, when these two things

1607
01:19:03,300 --> 01:19:04,100
come together.

1608
01:19:04,400 --> 01:19:07,300
And since they're always together in implementation, I

1609
01:19:07,400 --> 01:19:10,000
I would have expected maybe a more complete way of looking at it.

1610
01:19:10,500 --> 01:19:11,500
Does any of that make sense for you?

1611
01:19:11,500 --> 01:19:12,900
Just like I have no idea what you're asking.

1612
01:19:13,100 --> 01:19:15,000
Well, not not sure.

1613
01:19:15,000 --> 01:19:18,400
I know what you're asking, but okay, I'll say a few things related to

1614
01:19:18,400 --> 01:19:26,400
that, okay, so the extra symbols, that tells you you're adding are

1615
01:19:26,400 --> 01:19:28,900
totally hacky heuristic.

1616
01:19:28,900 --> 01:19:32,100
It's like, there's no rigorous Theory to it.

1617
01:19:33,100 --> 01:19:34,700
And there's a lot of possibilities.

1618
01:19:34,700 --> 01:19:36,800
There are different LZ, coders, add different things.

1619
01:19:36,900 --> 01:19:43,200
Okay, like, traditionally you, are you add a match, which is an offset

1620
01:19:43,200 --> 01:19:43,800
in a length.

1621
01:19:43,900 --> 01:19:46,700
Yes, modern LZ, coders.

1622
01:19:46,900 --> 01:19:48,100
Add other things there.

1623
01:19:48,800 --> 01:19:49,200
Okay.

1624
01:19:49,400 --> 01:19:49,800
You know.

1625
01:19:49,800 --> 01:19:55,100
So there's like, single literal matches, right?

1626
01:19:55,100 --> 01:19:57,400
There's Delta literals.

1627
01:19:57,400 --> 01:20:01,100
There's instead of offsets you might send rap, offsets things like

1628
01:20:01,100 --> 01:20:01,500
that.

1629
01:20:01,500 --> 01:20:02,700
Yeah, I do remember LZ.

1630
01:20:02,900 --> 01:20:07,700
Um, a had a number of special cases like this is a literal match.

1631
01:20:07,900 --> 01:20:13,000
I'd say, this is a match that has the same size as a pretty like, they

1632
01:20:13,000 --> 01:20:15,800
have like, weird things of like, we found this to be efficient.

1633
01:20:15,800 --> 01:20:17,000
So we write these everything.

1634
01:20:17,000 --> 01:20:20,200
It's, it's sort of you think of it as just like a toolbox yet.

1635
01:20:20,200 --> 01:20:24,900
Like, these are different ways of sending characters.

1636
01:20:24,900 --> 01:20:25,400
Yes.

1637
01:20:25,400 --> 01:20:27,000
You can kind of, add whatever you want there.

1638
01:20:27,000 --> 01:20:31,000
Yes, so like, broadly has some new weird things that it's added.

1639
01:20:31,000 --> 01:20:32,700
Do you say broadly or broccoli?

1640
01:20:32,800 --> 01:20:33,700
Broadly.

1641
01:20:33,800 --> 01:20:34,200
Okay.

1642
01:20:34,200 --> 01:20:37,400
So the Google I was hoping you said broccoli because I wanted there to

1643
01:20:37,400 --> 01:20:40,500
be a compressor going properly, but okay webp lost Liz has a similar

1644
01:20:40,500 --> 01:20:44,100
thing where I was like codebook, like, okay, trying to send pixels

1645
01:20:44,100 --> 01:20:49,800
losslessly but it can send pixels as like local palette selections

1646
01:20:49,800 --> 01:20:50,400
like that.

1647
01:20:50,400 --> 01:20:52,500
So it just has different modes there.

1648
01:20:53,000 --> 01:20:59,200
So, like you always have a literal as a fallback, yes, in case your

1649
01:20:59,200 --> 01:20:59,700
other

1650
01:21:00,200 --> 01:21:03,400
Don't you have to be able to send all their own, right?

1651
01:21:04,700 --> 01:21:06,500
But then you have these other codebook things.

1652
01:21:06,500 --> 01:21:11,600
They're just ways of grabbing characters and part of your LZ design

1653
01:21:11,600 --> 01:21:13,900
is, what do I add in there?

1654
01:21:14,000 --> 01:21:15,100
That is helpful.

1655
01:21:15,100 --> 01:21:17,100
Yes, and to some extent.

1656
01:21:17,100 --> 01:21:21,100
That's part of your modeling of different data will have different

1657
01:21:21,100 --> 01:21:24,300
types of things that are helpful there, okay?

1658
01:21:25,000 --> 01:21:29,100
Like whether your data is binary and has structured repeat patterns or

1659
01:21:29,600 --> 01:21:29,800
different.

1660
01:21:30,000 --> 01:21:30,600
Things like that.

1661
01:21:32,700 --> 01:21:41,300
So l z, in that sense is an over complete.

1662
01:21:42,300 --> 01:21:46,000
Alphabet for expressing data, right?

1663
01:21:46,000 --> 01:21:48,900
Because everything you send could be expressed, many different ways.

1664
01:21:48,900 --> 01:21:52,300
Using the LZ rate that you have it's what you've made your alphabet to

1665
01:21:52,300 --> 01:21:53,400
Big essentially, right?

1666
01:21:53,400 --> 01:21:53,800
Yes.

1667
01:21:53,800 --> 01:21:57,500
Your original B and B are minimal.

1668
01:21:57,800 --> 01:21:58,200
Yes.

1669
01:21:58,900 --> 01:22:00,600
And then now you're using an alphabet.

1670
01:22:00,600 --> 01:22:05,200
That's like yes it's got lots of overlap of lots of these simple sound

1671
01:22:05,200 --> 01:22:06,600
the same thing, right?

1672
01:22:08,100 --> 01:22:11,700
Which is a very strange thing in data compression because

1673
01:22:12,500 --> 01:22:13,400
That's doing that.

1674
01:22:13,400 --> 01:22:14,700
Is wasteful, right?

1675
01:22:14,700 --> 01:22:18,000
You're getting bigger as you get smaller which is a little

1676
01:22:18,000 --> 01:22:19,500
counterintuitive I know, right?

1677
01:22:19,500 --> 01:22:19,800
Yeah.

1678
01:22:20,500 --> 01:22:26,000
So like in traditional voters in the model coder setup you don't do

1679
01:22:26,000 --> 01:22:28,700
that kind of thing because it is wasteful, okay?

1680
01:22:29,600 --> 01:22:33,600
And in the theoretical analysis, you generally would not do that, want

1681
01:22:33,600 --> 01:22:33,900
us?

1682
01:22:35,300 --> 01:22:37,200
It it's just something that's practical.

1683
01:22:37,300 --> 01:22:37,600
Yeah,

1684
01:22:39,200 --> 01:22:43,000
And it turns out that the waste from that is not that bad.

1685
01:22:46,000 --> 01:22:51,200
There are interesting ways to look at getting rid of that waste have

1686
01:22:51,200 --> 01:22:52,300
been done and some Elves.

1687
01:22:52,300 --> 01:22:53,100
He's like,

1688
01:22:56,600 --> 01:23:04,700
For example, if a match that starts with the letter a is available,

1689
01:23:05,300 --> 01:23:10,000
then you know that the literal a should never be used that makes

1690
01:23:10,000 --> 01:23:17,100
perfect sense which means that you could in your code or sepsis, which

1691
01:23:17,100 --> 01:23:19,800
is saving you some space in your entropy go during I think.

1692
01:23:19,900 --> 01:23:23,000
So, every if you look at all your strings that you have,

1693
01:23:25,300 --> 01:23:26,300
You can get one.

1694
01:23:27,800 --> 01:23:31,300
It's not quite precise but things like that, right?

1695
01:23:31,300 --> 01:23:33,800
No, I get what you're saying, but yeah, like it.

1696
01:23:33,800 --> 01:23:39,500
You could you can instead of allowing the over complete alphabet, you

1697
01:23:39,500 --> 01:23:44,000
can say instead that once I have the ability to express something in

1698
01:23:44,000 --> 01:23:47,600
one way, I will eliminate the other ways I could have expressed it to

1699
01:23:47,600 --> 01:23:51,500
reduce the over completeness of relevant and maybe that's good, maybe

1700
01:23:51,500 --> 01:23:52,100
that's bad.

1701
01:23:52,100 --> 01:23:55,400
But, you know, I could so most

1702
01:23:56,100 --> 01:23:59,500
practical coders that we use these days are over complete.

1703
01:24:00,000 --> 01:24:05,300
Kind of interesting to me like all the video codecs are way way over

1704
01:24:05,300 --> 01:24:05,900
complete.

1705
01:24:06,000 --> 01:24:13,000
Yeah, in fact I remember this both both from pink to and also from

1706
01:24:13,000 --> 01:24:18,300
like ever looking at like mpeg-4 spec it's just it's I mean you can

1707
01:24:18,300 --> 01:24:24,300
encode the image as a hobby and he was saying, if you look at the

1708
01:24:24,700 --> 01:24:27,500
specs there's just billions and billions and billions of ways to

1709
01:24:27,500 --> 01:24:29,900
include even the same little tiny part of

1710
01:24:30,000 --> 01:24:30,500
An image.

1711
01:24:31,000 --> 01:24:40,000
So it turns out that being over complete and having an encoder that

1712
01:24:41,600 --> 01:24:45,500
spends a lot of time, considering the different choices is an

1713
01:24:45,500 --> 01:24:49,900
interesting design point, that seems to be the one that works it.

1714
01:24:49,900 --> 01:24:58,100
Yeah, it lets you basically use an encoder time to find a good bit

1715
01:24:58,100 --> 01:24:58,800
stream.

1716
01:25:00,100 --> 01:25:05,100
Right, that of kind of baking it into the bitstream, inherently, yes.

1717
01:25:05,100 --> 01:25:06,900
Which would cost you decoder time.

1718
01:25:06,900 --> 01:25:07,400
Got it.

1719
01:25:07,700 --> 01:25:09,900
So, you have kind of these.

1720
01:25:09,900 --> 01:25:15,000
Lots of different ways to encode data, all of which are efficient to

1721
01:25:15,000 --> 01:25:15,800
decode.

1722
01:25:17,300 --> 01:25:20,700
And then you're putting the work on the encoder search time to

1723
01:25:20,700 --> 01:25:22,100
consider all those ways.

1724
01:25:23,900 --> 01:25:24,700
That's pretty interesting.

1725
01:25:24,700 --> 01:25:28,400
So, in some sense you could think of it, as we've kind of got, if we

1726
01:25:28,400 --> 01:25:34,900
imagine, there's a uniform constant, that's like how much compression

1727
01:25:34,900 --> 01:25:42,500
plus time there is, we can choose to, like, move that time around and

1728
01:25:42,500 --> 01:25:45,300
get more compression by, like, sort of putting the time into the

1729
01:25:45,300 --> 01:25:47,800
compressor versus into the decompressor.

1730
01:25:47,800 --> 01:25:50,900
We can still get the same compression by just moving all the time,

1731
01:25:50,900 --> 01:25:53,500
over to the compressor and leaving the decompressor efficient.

1732
01:25:53,700 --> 01:25:56,900
Even though, you know, in some sense you could have gone the other way

1733
01:25:56,900 --> 01:25:58,600
I suppose maybe.

1734
01:25:58,800 --> 01:26:01,000
Although I guess I don't know if we know of ways to go the other way

1735
01:26:01,000 --> 01:26:02,600
but maybe it's possibly good.

1736
01:26:02,600 --> 01:26:03,100
It's very good.

1737
01:26:03,100 --> 01:26:05,200
Yeah it's something that we haven't really looked at sometimes.

1738
01:26:05,200 --> 01:26:08,000
Very rarely you don't want that spot case is often.

1739
01:26:08,100 --> 01:26:15,300
Yeah it's it's something I've seen also in terms of just entropy

1740
01:26:15,300 --> 01:26:20,300
coding that you have kind of two classic choices that you can do.

1741
01:26:21,000 --> 01:26:25,900
Adaptive entropy coding with a model the changes over time.

1742
01:26:25,900 --> 01:26:31,200
Yes with arithmetic coding or rants or something like this or you can

1743
01:26:31,200 --> 01:26:35,100
do something like Hoffman or tance Tas coating.

1744
01:26:35,100 --> 01:26:35,500
Okay.

1745
01:26:35,700 --> 01:26:38,800
That uses static models and sense the code lengths.

1746
01:26:39,100 --> 01:26:39,600
Okay.

1747
01:26:40,200 --> 01:26:42,600
So is TA NS technically.

1748
01:26:42,700 --> 01:26:47,600
What it is called if the RNs an RA NS is incredible version, T.

1749
01:26:47,600 --> 01:26:49,000
And S is the static version.

1750
01:26:49,600 --> 01:26:50,600
Well, or

1751
01:26:50,800 --> 01:26:51,400
Is it not?

1752
01:26:52,100 --> 01:26:53,200
Yes I'm sort of.

1753
01:26:53,200 --> 01:26:56,500
Okay, so ta + S stands for table based in us.

1754
01:26:56,600 --> 01:26:59,800
Okay, our ANS tents for range

1755
01:27:00,000 --> 01:27:00,500
Eunice.

1756
01:27:00,600 --> 01:27:04,500
Okay, which is by analogy to the range arithmetic.

1757
01:27:04,500 --> 01:27:05,400
Odor, got it.

1758
01:27:05,700 --> 01:27:06,800
And that is adaptive.

1759
01:27:06,800 --> 01:27:11,300
Those are both, just special cases of ANS and Jericho.

1760
01:27:11,500 --> 01:27:11,900
Okay.

1761
01:27:12,300 --> 01:27:17,200
So there are adaptive ens coders that are not rants coders.

1762
01:27:17,200 --> 01:27:21,700
I think, for example, in our static, there's a static version of

1763
01:27:21,700 --> 01:27:25,900
France, for example, got so tense is not the only static and US.

1764
01:27:26,100 --> 01:27:27,800
Those are just two particular ways to do it.

1765
01:27:27,900 --> 01:27:28,400
Got it.

1766
01:27:28,600 --> 01:27:29,900
So if you are doing static,

1767
01:27:30,000 --> 01:27:37,700
Attic entropy coding, you can spend time in the end coder, to find the

1768
01:27:38,000 --> 01:27:43,100
kind of similar regions of the file and cut it up, and separate

1769
01:27:43,100 --> 01:27:49,100
statistics for each one segment, so that can take a lot of encoder

1770
01:27:49,100 --> 01:27:49,600
search time.

1771
01:27:49,600 --> 01:27:51,100
It's a hard problem, right?

1772
01:27:51,900 --> 01:27:55,200
But the decoder is still fast because it already has a static data

1773
01:27:55,200 --> 01:27:55,800
that decoder.

1774
01:27:55,800 --> 01:27:59,800
Yeah, and that turns out to be very close in size.

1775
01:28:00,100 --> 01:28:01,900
To doing adaptive coating.

1776
01:28:02,300 --> 01:28:02,800
I see.

1777
01:28:03,800 --> 01:28:06,700
So you get almost a perfect way of taking

1778
01:28:08,000 --> 01:28:10,800
You know, an Adaptive coding your encoder and decoder or both

1779
01:28:10,800 --> 01:28:12,900
expensive, right?

1780
01:28:12,900 --> 01:28:17,200
Because the decoder has to be mimicking, the Adaptive work that really

1781
01:28:17,200 --> 01:28:20,300
encoder was doing and there's no way to get around that great

1782
01:28:20,300 --> 01:28:23,000
additional load, they have to be adapting in lockstep.

1783
01:28:23,300 --> 01:28:25,400
They have to always see the same model, right?

1784
01:28:26,500 --> 01:28:31,500
So by going to this static with encoder searching, yes, the decoder is

1785
01:28:31,500 --> 01:28:36,800
now cheap in the encoder is very expensive and wait so you're saying

1786
01:28:36,800 --> 01:28:37,600
even if in that

1787
01:28:37,700 --> 01:28:40,700
Case you're talking about literally, I'm sending statistics.

1788
01:28:40,700 --> 01:28:45,200
So I have to send a little block of turning 46, bytes or something.

1789
01:28:45,200 --> 01:28:45,600
For each.

1790
01:28:45,600 --> 01:28:48,300
One of these chunks to preload the statistics.

1791
01:28:48,400 --> 01:28:51,700
I mean, I don't know what exactly, but even given that, I had to send

1792
01:28:51,700 --> 01:28:55,300
that block, it's still close in size to the kind where I didn't have

1793
01:28:55,300 --> 01:28:57,600
to send anything, and I was just doing adaptive, correct.

1794
01:28:58,300 --> 01:29:01,300
That's what it can even be better in some cases, because, right?

1795
01:29:01,300 --> 01:29:04,000
Because depending on whether the Adaptive could get up to the correct

1796
01:29:04,000 --> 01:29:06,800
adapt adaptation because the B string

1797
01:29:08,100 --> 01:29:09,900
might not lend itself to that, I guess, right?

1798
01:29:09,900 --> 01:29:13,900
I mean, the the worst case is when the data is switching back and

1799
01:29:13,900 --> 01:29:15,200
forth rapidly, right?

1800
01:29:15,200 --> 01:29:19,700
Like if you have data that's like text in an image and then test and

1801
01:29:19,700 --> 01:29:20,900
then an image, right?

1802
01:29:21,000 --> 01:29:25,200
The static can actually find those transitions pretty easily, right?

1803
01:29:25,200 --> 01:29:29,100
Whereas the Adaptive has to adapt on every transition and if those, if

1804
01:29:29,100 --> 01:29:33,500
the if the size of each section isn't long enough, yet at application

1805
01:29:33,500 --> 01:29:36,800
may not get there by the time it has to go back to the next one.

1806
01:29:36,800 --> 01:29:37,700
And so on just I mean,

1807
01:29:37,900 --> 01:29:39,800
It depends the problem with the adapt.

1808
01:29:40,300 --> 01:29:44,600
The good thing about the static for that case, is that the

1809
01:29:44,600 --> 01:29:48,300
sophistication of your modeling is just in the end good or time,

1810
01:29:48,400 --> 01:29:48,800
right?

1811
01:29:49,100 --> 01:29:51,800
Whereas, with the Adaptive, if you're trying to make it smart enough

1812
01:29:51,800 --> 01:29:55,500
to realize, like, oh, here's a really sharp transition of Statistics.

1813
01:29:55,500 --> 01:29:59,000
I have to forget all my stuff quickly, the decoder has to do that same

1814
01:29:59,000 --> 01:29:59,800
backtrack, Nico.

1815
01:30:00,000 --> 01:30:04,500
Actually the same kind of analysis, so you aren't usually putting that

1816
01:30:04,500 --> 01:30:08,400
level of sophistication into your adaptive model to be able to detect

1817
01:30:08,700 --> 01:30:09,600
flush points.

1818
01:30:09,700 --> 01:30:10,400
That makes sense.

1819
01:30:13,200 --> 01:30:16,500
All right, so let me just close with.

1820
01:30:16,500 --> 01:30:19,200
Let me just see if I can ask one more time about that.

1821
01:30:19,400 --> 01:30:22,200
Just that the whole thing because I, I'm almost there, but I'm not

1822
01:30:22,200 --> 01:30:23,000
sure I'm quite there.

1823
01:30:23,000 --> 01:30:27,200
The answer may be that that we don't have any good explanation for

1824
01:30:27,200 --> 01:30:27,800
these sorts of things.

1825
01:30:27,800 --> 01:30:36,200
But so still on the, on the concept of the LZ, versus the arithmetic

1826
01:30:36,200 --> 01:30:37,000
side of things.

1827
01:30:42,800 --> 01:30:46,400
I think originally early on in the discussion, you said that l z is

1828
01:30:46,400 --> 01:30:48,700
understood as a modeling system.

1829
01:30:48,700 --> 01:30:52,500
Now and maybe originally it wasn't thought of that way or wasn't

1830
01:30:52,500 --> 01:30:55,000
immediately obvious that, that's how it should be looked at, right?

1831
01:30:55,000 --> 01:30:55,400
Wait.

1832
01:30:57,600 --> 01:31:02,000
So can you maybe just give a little bit more insight into that?

1833
01:31:02,000 --> 01:31:06,000
I guess, because I think that may also be part of the thing that I was

1834
01:31:06,000 --> 01:31:06,900
hung up on before.

1835
01:31:07,300 --> 01:31:12,400
Because again, it's just a little confusing to think about the way.

1836
01:31:12,700 --> 01:31:16,200
Something like arithmetic use symbols where you're talking about a

1837
01:31:16,200 --> 01:31:20,400
situation where you actually know what the symbols are versus

1838
01:31:20,400 --> 01:31:27,400
something like LZ where you, it seems to have this ability to create

1839
01:31:27,400 --> 01:31:29,900
its own symbols in that sense, right?

1840
01:31:29,900 --> 01:31:34,600
Meaning it's looking back into the stream of things that it's received

1841
01:31:34,600 --> 01:31:35,400
so far.

1842
01:31:35,500 --> 01:31:40,200
And it's saying what I'm trying to Output next is this portion of what

1843
01:31:40,200 --> 01:31:41,600
I've already seen, right?

1844
01:31:42,500 --> 01:31:44,900
And again, the part that just it's hard for me to wrap my brain around

1845
01:31:44,900 --> 01:31:49,800
is something like arithmetic thinks about things in terms of symbols

1846
01:31:49,800 --> 01:31:53,300
but seems to have no awareness of the fact that that sort of thing

1847
01:31:53,300 --> 01:31:53,600
could exist.

1848
01:31:53,600 --> 01:31:58,600
The idea that things I've already sent are in effect potentially

1849
01:31:58,600 --> 01:32:00,500
usable as symbols, right?

1850
01:32:00,500 --> 01:32:01,800
It doesn't have this notion.

1851
01:32:01,800 --> 01:32:05,400
It just has a notion of an alphabet that we've predetermined or

1852
01:32:05,400 --> 01:32:06,100
something like this, right?

1853
01:32:06,100 --> 01:32:09,000
Well, arithmetic is just an entropy encoder, right?

1854
01:32:09,000 --> 01:32:12,400
And so I'm just kind of curious about that dichotomy a little

1855
01:32:12,700 --> 01:32:13,200
like,

1856
01:32:16,000 --> 01:32:18,000
I guess another way to say it might be

1857
01:32:20,100 --> 01:32:23,900
Is there a is there really no thing.

1858
01:32:24,100 --> 01:32:28,100
Definition of something in between and entropy encoder and a modeling

1859
01:32:28,700 --> 01:32:29,400
system?

1860
01:32:29,700 --> 01:32:35,000
That is the thing that still has a symbol table, but it on a set of

1861
01:32:35,000 --> 01:32:36,500
symbols that it's thinking about that.

1862
01:32:36,500 --> 01:32:38,600
Those symbols are more dynamic.

1863
01:32:41,100 --> 01:32:44,700
Sorry, this is such a poorly phrased question, but like, okay, maybe,

1864
01:32:44,700 --> 01:32:48,600
let's just let me just say it in the most laymen way possible and you

1865
01:32:48,600 --> 01:32:50,200
can see if you can make anything of it.

1866
01:32:51,100 --> 01:32:55,600
There seems to be a world of difference to me so between like jpg,

1867
01:32:55,600 --> 01:32:59,800
like I'm going to DCT transform this thing into a set of numbers.

1868
01:33:00,600 --> 01:33:02,700
And then I'm going to think of that as my model.

1869
01:33:02,700 --> 01:33:07,800
So my model is I take my input set idct at first, that's a step.

1870
01:33:07,900 --> 01:33:14,000
That feels a particular way that doesn't feel like in its core.

1871
01:33:14,000 --> 01:33:16,500
It's thinking about symbols per se.

1872
01:33:17,000 --> 01:33:19,800
It's feels like a totally separate kind of an operation.

1873
01:33:19,800 --> 01:33:22,000
It's like a modeling, transform operation.

1874
01:33:23,300 --> 01:33:28,300
LZ while obviously not quite so specific and symbol.

1875
01:33:28,300 --> 01:33:32,700
And as something like an arithmetic or Huffman encoder, it still feels

1876
01:33:32,700 --> 01:33:33,500
very much.

1877
01:33:33,500 --> 01:33:35,500
Like it's thinking of things in terms of symbols.

1878
01:33:35,500 --> 01:33:36,400
In that way.

1879
01:33:36,700 --> 01:33:40,900
It feels a lot less like a DCT and a lot more like an arithmetic

1880
01:33:40,900 --> 01:33:41,600
encoder to me.

1881
01:33:41,600 --> 01:33:42,800
When I think about it,

1882
01:33:44,000 --> 01:33:46,600
Yet it is not that or something.

1883
01:33:46,900 --> 01:33:49,600
Does that have any more of it?

1884
01:33:49,600 --> 01:33:50,600
Like, do you see why?

1885
01:33:50,600 --> 01:33:55,000
I think of those those things that I'm having trouble policing LZ as a

1886
01:33:55,000 --> 01:33:56,300
thing in that way.

1887
01:33:56,300 --> 01:34:01,300
And maybe it's just like, yeah, that's the way it is.

1888
01:34:02,000 --> 01:34:03,100
Yeah, okay.

1889
01:34:03,200 --> 01:34:04,700
So I mean there's just

1890
01:34:06,200 --> 01:34:07,900
There's theoretical question.

1891
01:34:08,100 --> 01:34:12,200
Yeah, and then there's just algorithms that work, okay?

1892
01:34:12,400 --> 01:34:16,600
It's just a way of working with the data and expressing things, okay?

1893
01:34:18,200 --> 01:34:22,300
And so, a couple of points, all right, one is that

1894
01:34:24,400 --> 01:34:29,500
You can always see how a compressor corresponds to a model just by

1895
01:34:29,500 --> 01:34:32,000
looking at the number of bits that it outputs.

1896
01:34:32,800 --> 01:34:33,300
Okay?

1897
01:34:33,400 --> 01:34:38,800
So if I run my lz77 up to a certain point in the file, okay?

1898
01:34:39,900 --> 01:34:47,400
Then I can try adding on each of the next 256 possible characters.

1899
01:34:47,400 --> 01:34:47,900
Yes.

1900
01:34:48,600 --> 01:34:53,500
Give it that character to encode and see how many bits it outputs for

1901
01:34:53,500 --> 01:34:54,000
each one.

1902
01:34:54,100 --> 01:34:54,600
Okay.

1903
01:34:56,100 --> 01:35:02,400
That bit count, if I go to, to the length on each one is a probability

1904
01:35:03,300 --> 01:35:04,200
for, yes.

1905
01:35:04,200 --> 01:35:04,600
Possible.

1906
01:35:04,600 --> 01:35:08,900
Following symbol got it, which is a way of turning any compressor into

1907
01:35:08,900 --> 01:35:09,500
a model.

1908
01:35:10,500 --> 01:35:11,100
I understand.

1909
01:35:11,400 --> 01:35:15,400
So you can take the most heuristic hacky compressor in the world and

1910
01:35:15,400 --> 01:35:20,800
always figure out what model is this actually corresponding to.

1911
01:35:21,100 --> 01:35:21,700
I see.

1912
01:35:21,800 --> 01:35:25,300
So at any, instantaneous, point in a

1913
01:35:26,800 --> 01:35:31,000
I can look at the probability that y.

1914
01:35:31,000 --> 01:35:34,800
Sorry, I can look at the amount of bits that this thing will output

1915
01:35:34,900 --> 01:35:37,400
for any of the possible things that could come next.

1916
01:35:37,900 --> 01:35:41,700
And in a sense I have basically said okay, that is the probabilistic

1917
01:35:41,700 --> 01:35:42,800
model of this thing.

1918
01:35:42,900 --> 01:35:45,100
Now, it is not order.

1919
01:35:45,100 --> 01:35:48,700
Zero in the case of LZ, it depends entirely on all the stuff that came

1920
01:35:48,700 --> 01:35:52,700
before it, but at any instantaneous point, I can still just look at

1921
01:35:52,700 --> 01:35:55,200
the order zero right here, in some sense.

1922
01:35:55,500 --> 01:35:59,900
And get that at least unwinding the rest of it may be impossible to.

1923
01:36:00,000 --> 01:36:03,300
Is it some crazy turing machine, who knows what the, you know what

1924
01:36:03,300 --> 01:36:03,900
it's doing?

1925
01:36:04,200 --> 01:36:06,800
But just instantaneously I can look at it that way.

1926
01:36:06,800 --> 01:36:07,200
Great.

1927
01:36:07,300 --> 01:36:10,900
Yeah, that's the probability of, what is the next character, given?

1928
01:36:10,900 --> 01:36:12,500
All the previous characters?

1929
01:36:12,600 --> 01:36:13,200
Yes, right.

1930
01:36:14,100 --> 01:36:17,700
So, every compressor is a model in that sense tells he's got a way of

1931
01:36:18,500 --> 01:36:20,500
getting to that output links.

1932
01:36:21,100 --> 01:36:23,000
Okay, that makes a lot of sense.

1933
01:36:23,900 --> 01:36:24,300
Okay?

1934
01:36:25,700 --> 01:36:31,900
The other thing is that so the you can think of the extra symbols.

1935
01:36:33,300 --> 01:36:40,500
As ways of kind of getting to the arithmetic coder.

1936
01:36:42,100 --> 01:36:54,300
I can see this clearly but so like say you have a model that is just

1937
01:36:54,300 --> 01:36:56,800
predicting its most likely guess.

1938
01:36:57,700 --> 01:37:00,200
For the next symbol.

1939
01:37:00,400 --> 01:37:00,800
Okay.

1940
01:37:00,800 --> 01:37:06,200
Like it makes one guess and then it if it's right, it outputs a 0 bit,

1941
01:37:06,500 --> 01:37:06,700
okay?

1942
01:37:06,700 --> 01:37:08,700
If it's wrong, it outputs a 1 bit.

1943
01:37:08,700 --> 01:37:12,000
In fact what the character actually was got it right tonight, that's

1944
01:37:12,100 --> 01:37:12,700
got it.

1945
01:37:13,400 --> 01:37:16,800
So what we've actually done there is added and then another simple.

1946
01:37:17,100 --> 01:37:21,800
Okay that'd so we have our literal we've added the yes/no bit more

1947
01:37:21,900 --> 01:37:23,300
accurate inaccurate that

1948
01:37:29,500 --> 01:37:31,700
We're outputting 04, right?

1949
01:37:31,800 --> 01:37:36,400
And one, and then eight more bits, right?

1950
01:37:36,700 --> 01:37:37,400
If we're wrong.

1951
01:37:42,300 --> 01:37:45,500
You can think of this as a combined, alphabet.

1952
01:37:46,600 --> 01:37:51,900
This, this is the symbols 0 to 255 that are literals.

1953
01:37:53,700 --> 01:37:55,400
This is symbol 256.

1954
01:37:57,000 --> 01:38:02,300
Okay, and I'm giving this a 1 B code and these all get a 9 bit code,

1955
01:38:02,700 --> 01:38:03,200
got it.

1956
01:38:03,400 --> 01:38:05,300
So this is my like super simple LZ.

1957
01:38:05,500 --> 01:38:06,100
Okay.

1958
01:38:06,300 --> 01:38:11,100
And I've added a symbol to my alphabet to specify hey my guess is

1959
01:38:11,100 --> 01:38:11,600
right.

1960
01:38:12,000 --> 01:38:12,500
Okay.

1961
01:38:13,000 --> 01:38:17,300
So all LZ is is doing more of this, okay?

1962
01:38:17,500 --> 01:38:21,600
I'm more complicated set of possible adding more special symbols okay,

1963
01:38:21,600 --> 01:38:22,900
giving them special codes.

1964
01:38:23,100 --> 01:38:23,500
Okay.

1965
01:38:24,100 --> 01:38:24,700
And

1966
01:38:28,700 --> 01:38:32,200
That's that's what heuristic compressors General to are doing.

1967
01:38:32,400 --> 01:38:34,900
And the reason why you don't

1968
01:38:35,900 --> 01:38:37,900
Why nlz compressor.

1969
01:38:38,900 --> 01:38:46,000
Itself isn't concerned about how to encode things, in the correct

1970
01:38:46,000 --> 01:38:52,300
number of bits is because fundamentally speaking, at least so far,

1971
01:38:53,400 --> 01:38:58,400
nobody has figured out any particular reason why the way you would do

1972
01:38:58,400 --> 01:38:59,000
that.

1973
01:38:59,100 --> 01:38:59,800
Would differ from

1974
01:39:00,000 --> 01:39:02,200
Just arithmetic, Ali, encoding.

1975
01:39:02,200 --> 01:39:06,900
The actual things that the LZ is doing right, because in some sense,

1976
01:39:06,900 --> 01:39:07,700
you can think of an arithmetic.

1977
01:39:07,700 --> 01:39:10,500
Encoder is a thing that's trying to figure out.

1978
01:39:10,500 --> 01:39:11,800
Well, not trying to figure out.

1979
01:39:11,800 --> 01:39:17,900
If it's a machine for correctly, outputting the minimal number of bits

1980
01:39:17,900 --> 01:39:18,400
to encode.

1981
01:39:18,400 --> 01:39:21,200
This set of symbols that is trying to input, right?

1982
01:39:21,600 --> 01:39:24,600
The LZ encoder is not concerned with doing that.

1983
01:39:24,600 --> 01:39:27,900
It's not concerned with trying to get the optimum number of bits.

1984
01:39:28,000 --> 01:39:30,000
It's just trying to produce a series of

1985
01:39:30,000 --> 01:39:33,300
as of match versus not match and it wants to reduce the middle number

1986
01:39:33,300 --> 01:39:33,900
of bits.

1987
01:39:35,300 --> 01:39:38,500
With that in mind, but it's not trying to get down to fractional or

1988
01:39:38,500 --> 01:39:39,300
anything like that.

1989
01:39:40,800 --> 01:39:45,600
So you might say the reason why it's not concerned with that is

1990
01:39:45,600 --> 01:39:49,400
because the way that we have chosen to try to approach that is just,

1991
01:39:49,400 --> 01:39:53,500
it seems like bolting an arithmetic encoder onto the back of it is as

1992
01:39:53,500 --> 01:39:56,900
efficient as trying to figure out a way to integrate that directly

1993
01:39:56,900 --> 01:39:58,500
into the LZ scheme.

1994
01:40:01,200 --> 01:40:03,300
Because like in a fanciful world, right?

1995
01:40:03,600 --> 01:40:06,800
And again, from Layman's perspective, you could imagine an LZ encoder

1996
01:40:06,800 --> 01:40:09,400
that itself was working on fractional B.

1997
01:40:09,700 --> 01:40:13,200
I don't know what that exactly means but like the concept that I have

1998
01:40:13,200 --> 01:40:20,100
to copy out of a 8 bit at a time, bitstream doesn't really have to

1999
01:40:20,100 --> 01:40:22,200
happen like an LZ encoder.

2000
01:40:22,200 --> 01:40:26,800
Could a similar thing to know seeking encoder could maybe be done

2001
01:40:27,200 --> 01:40:30,200
imagining working on an infinite fraction grabbing parts of the

2002
01:40:30,600 --> 01:40:33,400
Fraction out, which means that now it's fractional B in terms of the

2003
01:40:33,400 --> 01:40:36,400
input, I'm making this up, but you see what I mean, right?

2004
01:40:36,500 --> 01:40:36,800
Yeah.

2005
01:40:37,200 --> 01:40:41,500
I mean, so we usually work on B just out of practicality, right?

2006
01:40:41,500 --> 01:40:45,700
There's no inherent theoretical reason why we have to write and like

2007
01:40:45,700 --> 01:40:49,500
the careful people in the literature will do their arithmetic coding

2008
01:40:49,500 --> 01:40:52,100
in terms of Base B, right?

2009
01:40:52,100 --> 01:40:53,200
Right is arbitrate arbitrate.

2010
01:40:53,200 --> 01:40:53,400
Yeah.

2011
01:40:53,400 --> 01:40:57,400
But it, you know, as a programmer reading it rice.

2012
01:40:57,400 --> 01:41:00,100
Think that's two right, right, right, right.

2013
01:41:00,300 --> 01:41:01,300
I'm not doing yeah.

2014
01:41:01,700 --> 01:41:03,100
Like ternary right?

2015
01:41:03,100 --> 01:41:03,900
Like arithmetic.

2016
01:41:04,000 --> 01:41:07,000
Ok, so that's all possible.

2017
01:41:07,000 --> 01:41:13,200
Yeah, there are more General things, so let me in terms of l z,

2018
01:41:15,200 --> 01:41:18,600
You could at each step of your coating.

2019
01:41:19,400 --> 01:41:23,000
Look at like in the LZ aspect of it.

2020
01:41:23,000 --> 01:41:23,500
Yes.

2021
01:41:23,600 --> 01:41:26,600
Before we get to the entropy coding, yes, we could.

2022
01:41:26,600 --> 01:41:29,700
Look at like, hey, some of my heuristic code.

2023
01:41:29,700 --> 01:41:33,800
Words are not even possible in this location where I am.

2024
01:41:33,800 --> 01:41:39,400
Yes, so let me exclude them from my code words, like maybe early on in

2025
01:41:39,400 --> 01:41:40,000
the file.

2026
01:41:40,000 --> 01:41:41,900
You don't have much dictionary, right?

2027
01:41:41,900 --> 01:41:44,500
So there's lots of things that aren't possible, like, Laura offsets

2028
01:41:44,500 --> 01:41:44,600
aren't

2029
01:41:45,100 --> 01:41:45,800
Right.

2030
01:41:46,000 --> 01:41:48,900
Maybe you haven't even seen all the literals.

2031
01:41:49,000 --> 01:41:50,000
Yes a lot.

2032
01:41:50,000 --> 01:41:52,300
You know you can't possibly match them and forget that.

2033
01:41:53,600 --> 01:41:57,100
So you could be doing more at that step in the LZ, right?

2034
01:41:57,900 --> 01:41:59,300
And people have tried it there.

2035
01:41:59,300 --> 01:41:59,800
Ben

2036
01:42:00,600 --> 01:42:05,800
There's lots of variants along there, there's things like L ZF g l zp

2037
01:42:08,100 --> 01:42:08,700
p more recently.

2038
01:42:08,700 --> 01:42:13,500
There's Cannon Konya and Kennen Conrad's were country which is kind of

2039
01:42:13,500 --> 01:42:15,000
an interesting thing in this direction.

2040
01:42:15,100 --> 01:42:15,600
Okay.

2041
01:42:15,900 --> 01:42:22,200
For the most part spending CPU work there is not a good trade-off,

2042
01:42:22,300 --> 01:42:22,700
okay?

2043
01:42:24,100 --> 01:42:27,200
That they're just better places to park CPU work.

2044
01:42:27,200 --> 01:42:29,600
Okay so I mean to some extent

2045
01:42:30,200 --> 01:42:31,600
The answer there is.

2046
01:42:32,700 --> 01:42:36,700
Compression is always an issue of design of where your where you

2047
01:42:36,700 --> 01:42:41,200
putting your CPU work, got it and you know, there's always options.

2048
01:42:42,100 --> 01:42:45,400
You know, there's no shortage of ways, we can increase the amount of

2049
01:42:45,400 --> 01:42:46,100
CPU work.

2050
01:42:46,100 --> 01:42:47,800
I can always do some more modeling.

2051
01:42:47,800 --> 01:42:48,300
Yeah.

2052
01:42:48,300 --> 01:42:49,600
There's always you know,

2053
01:42:52,600 --> 01:42:57,700
So one of the there's like like all the redundancies and the over

2054
01:42:57,700 --> 01:43:02,300
completeness of the LC you could model and eliminate if you wanted to

2055
01:43:02,300 --> 01:43:03,600
spend the CPU work on it.

2056
01:43:03,600 --> 01:43:04,000
Yes.

2057
01:43:04,100 --> 01:43:04,900
But it takes work.

2058
01:43:05,000 --> 01:43:08,700
Yes, there's correlations all over the place and LZ that we know are

2059
01:43:08,700 --> 01:43:10,800
there and we could model and take out.

2060
01:43:10,800 --> 01:43:17,000
Okay, like the previous character, for example, predicts a lot about

2061
01:43:17,000 --> 01:43:21,000
what the current sequence, what the current symbol is going to be or

2062
01:43:21,000 --> 01:43:21,500
whether it's a

2063
01:43:22,300 --> 01:43:29,500
Okay, and the previous occurrence of the same match.

2064
01:43:29,600 --> 01:43:31,600
Like once I send my offset,

2065
01:43:33,100 --> 01:43:37,200
I know, I can go back to that spot in the file because I've sent the

2066
01:43:37,200 --> 01:43:38,100
offsets the decoder.

2067
01:43:38,100 --> 01:43:39,300
Could do the same thing, right?

2068
01:43:39,300 --> 01:43:41,800
I can look around that offset at the data there.

2069
01:43:42,500 --> 01:43:45,000
It's probably very similar to where I am now.

2070
01:43:45,300 --> 01:43:49,300
Okay, so I could be using that information, but I'm not to predict

2071
01:43:49,300 --> 01:43:50,800
things about my local neighborhood.

2072
01:43:50,800 --> 01:43:55,100
I say, but I'm not other than, you know, obviously you're copying the

2073
01:43:55,100 --> 01:44:00,100
match but even outside of the match region, there will be similarity

2074
01:44:00,100 --> 01:44:01,200
stuff that you might want to know.

2075
01:44:01,300 --> 01:44:01,700
Yeah.

2076
01:44:03,000 --> 01:44:06,700
So, there's lots of opportunities and it's just like, what can you

2077
01:44:06,700 --> 01:44:07,600
express?

2078
01:44:07,600 --> 01:44:13,600
Well, that is efficient enough because this beats, we want to run out.

2079
01:44:13,600 --> 01:44:17,500
Now, we don't have a lot of time.

2080
01:44:17,500 --> 01:44:19,300
I'm still doing much of anything.

2081
01:44:19,300 --> 01:44:23,700
Got it, you know, are in the decoder and the encoder you can afford to

2082
01:44:23,700 --> 01:44:27,200
be slow, I suppose it was certainly, that's the, I mean,

2083
01:44:28,400 --> 01:44:32,700
The design point that we work at a Trad usually is slower and coders.

2084
01:44:32,700 --> 01:44:38,100
That's that's what the odors and we only get like one to ten clocks

2085
01:44:38,200 --> 01:44:40,300
per symbol in the decoder.

2086
01:44:40,800 --> 01:44:41,300
Gotcha.

2087
01:44:41,300 --> 01:44:43,900
So you can't do very much they're right?

2088
01:44:45,100 --> 01:44:50,600
All right, so in addition to that, so like if you look at LZ,

2089
01:44:51,800 --> 01:44:54,800
There's lots of points where you can see that we're wasting that's

2090
01:44:54,900 --> 01:44:55,300
okay.

2091
01:44:55,300 --> 01:44:59,600
And it's just a question of, how do we get them without spending too

2092
01:44:59,600 --> 01:44:59,900
much time?

2093
01:45:01,200 --> 01:45:05,000
You're also, there's also, of course, like, another level of things

2094
01:45:05,000 --> 01:45:07,100
you're missing that LC don't model.

2095
01:45:07,100 --> 01:45:07,500
Well.

2096
01:45:07,700 --> 01:45:08,200
Okay.

2097
01:45:08,300 --> 01:45:13,400
So there's a whole other issue of like, what other compression is

2098
01:45:13,400 --> 01:45:15,300
available in this file, right?

2099
01:45:15,300 --> 01:45:15,600
Right.

2100
01:45:15,600 --> 01:45:17,300
I'm never going to get with LZ, right?

2101
01:45:17,300 --> 01:45:20,100
Let the preconditioning sorts of stuff like different thing from

2102
01:45:20,100 --> 01:45:21,400
symbols or things like this.

2103
01:45:21,400 --> 01:45:24,300
It people have added to LZ I guess in.

2104
01:45:24,500 --> 01:45:28,400
Like I think lzma has some things like this of this nature, right?

2105
01:45:28,400 --> 01:45:30,800
Where it'll Delta symbols from me?

2106
01:45:31,000 --> 01:45:34,000
Other things like that before encoding or stuff like this, which is

2107
01:45:34,000 --> 01:45:35,400
not technically in the LZ scheme.

2108
01:45:35,400 --> 01:45:36,500
I think great great.

2109
01:45:36,500 --> 01:45:36,800
Yeah.

2110
01:45:38,300 --> 01:45:38,600
All right.

2111
01:45:38,600 --> 01:45:39,800
Well I think that's everything.

2112
01:45:40,300 --> 01:45:42,100
Thank you so much for explaining all of that.

2113
01:45:42,800 --> 01:45:46,900
That's been very very very helpful and hopefully we've got it looks

2114
01:45:46,900 --> 01:45:47,900
like everything.

2115
01:45:48,400 --> 01:45:52,300
Looks like everything went well enough, people seem to have been able

2116
01:45:52,300 --> 01:45:55,600
to have heard us even even though we have our happy little webcam.

2117
01:45:56,100 --> 01:45:58,200
So thank you so much Charles that's been awesome.

2118
01:45:58,200 --> 01:46:01,300
I will post this along with the handmade con one server and can get

2119
01:46:01,300 --> 01:46:07,300
the complete package and yeah I guess also at some point people

2120
01:46:07,300 --> 01:46:07,900
probably should

2121
01:46:08,100 --> 01:46:09,000
Take a look at your blog.

2122
01:46:09,000 --> 01:46:10,600
There's a lot of compression stuff on there.

2123
01:46:11,400 --> 01:46:15,800
Should I include the shock tube the URL with this video, potentially,

2124
01:46:15,800 --> 01:46:17,800
or do you just use, like, no block?

2125
01:46:17,800 --> 01:46:18,700
The blog is secret.

2126
01:46:18,700 --> 01:46:19,700
Don't come to it.

2127
01:46:21,600 --> 01:46:24,100
Yeah, we can include the URL, right, I'll put it on the bottom.

2128
01:46:24,400 --> 01:46:25,500
Thanks so much for being here.

2129
01:46:26,100 --> 01:46:28,700
I will go ahead and I will close down the stream.

